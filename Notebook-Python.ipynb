{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c569ea4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PROJET ANALYSE DE DONNEES\n",
    "## Etude des stations de location de vélos dans Paris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00b7c09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.patches as mpatches\n",
    "import plotly.express as px\n",
    "import plotly.express as px\n",
    "import prince\n",
    "from prince import CA\n",
    "%matplotlib inline\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score \n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9de61a",
   "metadata": {},
   "source": [
    "Dans ce notebook, nous allons étudier un jeu de données contenant des informations concernant les taux de disponibilités des vélos dans des stations Vélib parisiennes. Nous avons accès à ce taux pour toutes les heures de chaque jour de la semaine sur la période du 2 septembre au 7 septembre 2014."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f814b2e",
   "metadata": {},
   "source": [
    "Une remarque importante pour comprendre au mieux le sujet est que plus le taux est proche de 1 plus la station a de vélos disponibles. Inversement, quand ce taux est proche de 0 alors il y a de moins en moins de vélos dans la station."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0b69e3-0ba5-419b-9a5d-8d432f91a180",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## 1. Présentation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae75747-2e71-44d5-810a-f7151f8979ac",
   "metadata": {},
   "source": [
    "Nous allons ici importer toutes les données mises à notre disposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e91809-f358-4cf9-aebb-32e54a0cf1f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#loading = pd.read_csv('velibLoading.csv', sep = \" \")\n",
    "loading = pd.read_csv('data/velibLoading.csv', sep = \" \")\n",
    "loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bf8fb2-771f-4266-8107-234f049bf7f2",
   "metadata": {},
   "source": [
    "Il y a 168 colonnes qui représentent le total des heures dans une semaine. Les 1189 lignes correspondent aux données de toutes les stations de Paris étudiées.\n",
    "\n",
    "On affiche ensuite les statistiques descriptives de ce jeu de données. Ici encore les 168 colonnes represéntent chaque heure d'une semaine et les lignes correspondent aux différentes statistiqus calculées à partir du jeu de données précédent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffddebcf-f12b-4793-a55f-3a282997b55f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loading.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5241dbd9-4f74-44d8-9e7a-6c7cefc1b4a2",
   "metadata": {},
   "source": [
    "Nous allons maintenant importer les coordonnées géographiques de chaque station. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bee9495-4237-4b3f-8bb6-1997977e15f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#coord = pd.read_csv('velibCoord.csv', sep = \" \")\n",
    "coord = pd.read_csv('data/velibCoord.csv', sep = \" \")\n",
    "\n",
    "coord.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb7edf2-f521-4b8d-b479-2f79967415d5",
   "metadata": {},
   "source": [
    "Le jeu de données Coord contient 4 variables: \\\n",
    "1 - position : la latitude et la longitude des 1189 stations \\\n",
    "2 - dates : la date de téléchargement \\\n",
    "3 - bonus : si bonus=1, la station est en altitude et si bonus=0 elle ne l'est pas \\\n",
    "4 - names : le nom des stations. \\\n",
    "Les lignes représentent les stations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b10ef8-16d9-4ffc-8bb5-cd24304751d6",
   "metadata": {},
   "source": [
    "Nous regardons dans le tableau de données si certaines données sont manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da33a2c-70e5-404e-bc0b-dfe3c1d0cd54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Nombre de données manquantes dans 'loading':\")\n",
    "print(loading.isna().sum().sum())\n",
    "print(\"Nombre de données manquantes dans 'coord':\")\n",
    "print(coord.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f3e5d9-4915-43c7-a688-b3f2e8df5e22",
   "metadata": {},
   "source": [
    "Or ici, le résultat obtenu pour chaque tableau \"loading\" et \"coord\" est 0, il n'y a donc pas de donnée manquante ! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566d4ee8-21f1-49ce-808c-2a77a9e771b6",
   "metadata": {},
   "source": [
    "Nous affichons ici le nombre d'occurences de chaque station dans nos données, par ordre décroissant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86e3145-f82a-4dc0-8b8d-d1b15061523c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"---Données duppliquées---\")\n",
    "station_name = coord.names.value_counts()\n",
    "print(station_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46855805-9322-47da-8608-23c75fb874df",
   "metadata": {},
   "source": [
    "Le tableau ci-dessous illustre le fait que même si le nom de la station apparaît trois fois dans notre jeu de données, celle-ci ne correspond pas aux mêmes coordonnées géographiques. Cela nous montre bien qu'il ne faut pas supprimer des lignes car même si les stations ont le même nom elles n'ont pas les mêmes caractéristiques géographiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063afb1d-3494-4eac-8f0a-664cfca39f71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name = station_name.index[0]\n",
    "coord[coord.names == name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4524a4-4096-48d4-b34c-c51a76cf9d4b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Analyse descriptive des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a1cf1c-1fe4-4c79-bd1d-de33a60f2c04",
   "metadata": {},
   "source": [
    "Afin de poursuivre notre analyse nous allons nous pencher sur le point de vue descriptif."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c972cf3c-b5f0-41d7-a019-850906c4b04f",
   "metadata": {},
   "source": [
    "Pour visualiser un peu mieux ces taux de chargement on affiche aussi le chargement sur la semaine pour 16 stations pris aléatoirement. On peut voir que certaines stations ont des cycles de chargement distinctifs, certaines se chargent la nuit et d'autres le jour, certaines ont un faible taux de chargement toute la semaine, et d'autres ont un profil de chargement distinct entre la semaine et le week-end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22153e7-ded3-47c9-85eb-69934741c637",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stations = np.arange(loading.shape[0])\n",
    "rd.shuffle(stations)\n",
    "stations = stations[:16] \n",
    "\n",
    "# --- #\n",
    "n_steps    = loading.shape[1] \n",
    "fig, axs = plt.subplots(4, 4, figsize = (15,12))\n",
    "time_range = np.linspace(1, n_steps, n_steps) \n",
    "\n",
    "\n",
    "timeTick = np.arange(1, 25*7, 24)\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        k_station = stations[4 * i + j]\n",
    "        axs[i, j].plot(time_range, loading.iloc[k_station, :], linewidth = 1, color = 'purple')\n",
    "        axs[i, j].vlines(x = timeTick, ymin = 0, ymax = 1, colors = \"orange\", linestyle = \"dotted\", linewidth = 3)\n",
    "        axs[i, j].set_title(coord.names[1 + k_station], fontsize = 12)\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set_xlabel('Time', fontsize = 12)\n",
    "    ax.set_ylabel('Loading', fontsize = 12)\n",
    "    ax.tick_params(axis='x', labelsize=10)\n",
    "    ax.tick_params(axis='y', labelsize=10)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c1e61f-b817-4358-9b4a-401ab22c44a0",
   "metadata": {},
   "source": [
    "Observons tout d'abord que les différentes moyennes des stations ne sont pas du tout homogène, et qu'il est donc, intéressant de regarder d'un peu plus près les différentes moyennes observées pour avoir une vision globale de l'impact des heures, jours et de la localisation des stations sur la comportement d'utilisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c252b7a-59b1-4cd8-a321-dea9fa91245d",
   "metadata": {},
   "source": [
    "En effet, dans le graphe suivant, il est possible de voir que le taux de chargement moyen varie grandement d'une station à une autre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331311aa-1f4d-4fe4-89b9-2010c495c724",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loading_mean = pd.Series(loading.mean(axis=1))\n",
    "# %load solutions/Python/plot_mean_stations.py\n",
    "n_stations = loading.shape[0]  # number of observed stations\n",
    "stations   = np.arange(n_stations)\n",
    "\n",
    "plt.figure(figsize = (20,6))\n",
    "\n",
    "# --- #\n",
    "\n",
    "plt.plot(loading_mean)\n",
    "plt.hlines(y = loading.mean().mean(), xmin=0, xmax=n_stations, \n",
    "           colors = \"OrangeRed\", linewidth = 3)\n",
    "\n",
    "# --- #\n",
    "\n",
    "plt.xlabel('Stations', fontsize = 20)\n",
    "plt.ylabel('Average loading', fontsize = 20)\n",
    "plt.title(\"Average loading per station\", fontsize = 25)\n",
    "plt.xticks(fontsize = 15)\n",
    "plt.yticks(fontsize = 15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62aa1f9e-1ee5-4e40-861d-45cf6b810d0b",
   "metadata": {},
   "source": [
    "Dans un contexte un peu plus général, on affiche la moyenne de chargement totale sur toutes les stations au cours de la semaine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8a7749-8f0e-47c5-b0a4-8b538535e0cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(loading.mean().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55653ed2-718c-40ea-96a5-ec2ad29b84ca",
   "metadata": {},
   "source": [
    "Ainsi, on peut dire qu'en moyenne, sur l'ensemble des stations parisiennes et sur une semaine, le taux de chargement moyen est de 0.39. Ce qui signifie qu'en moyenne il y a 4 vélos sur 10 disponibles dans les stations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307bf6dc",
   "metadata": {},
   "source": [
    "On s'intéresse ici au chargement moyen de toutes les stations en fonction de l'heure (chaque courbe correspond à un jour) et en noire la moyenne sur les jours de ce chargement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49388be1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# On calcule la moyenne pour chaque jour de la semaine\n",
    "mean_per_hour_per_day = loading.mean(axis = 0).to_numpy()\n",
    "mean_per_hour_per_day = mean_per_hour_per_day.reshape((7, 24))\n",
    "\n",
    "mean_per_hour = mean_per_hour_per_day.mean(axis=0)\n",
    "\n",
    "# --- #\n",
    "\n",
    "days = [\"Lundi\", \"Mardi\", \"Mercredi\", \"Jeudi\", \"Vendredi\", \"Samedi\", \"Dimanche\"]\n",
    "plt.figure(figsize = (15,10))\n",
    "\n",
    "plt.plot(mean_per_hour_per_day.transpose())\n",
    "plt.plot(mean_per_hour, color = \"black\", linewidth = 3)\n",
    "\n",
    "plt.xlabel('Chargement horaire, moyenne de toutes les stations', fontsize = 20)\n",
    "plt.ylabel('Chargement', fontsize = 20)\n",
    "plt.legend(days + ['Semaine'])\n",
    "plt.xticks(ticks = np.arange(0,24,4), labels=np.arange(0,24,4), fontsize = 15)\n",
    "\n",
    "plt.tight_layout\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99763d13-c729-443b-82f0-ca27783f411a",
   "metadata": {},
   "source": [
    "Ainsi, on peut voir qu'en moyenne, aux alentours de 2h-4h du matin les vélos ne sont pas beaucoup empruntés. Cependant, on peut voir qu'à 9h environ ils le sont davantage, idem entre 19h et 20h. Ce résultat s'explique par les heures de travail de la population qui part le matin en vélo et rentre en fin de journée. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41694f4-f2f7-451b-9d69-fe2ff81e037f",
   "metadata": {},
   "source": [
    "On souhaite savoir, en moyenne, quel est le jour de la semaine, durant lequel les gens utilisent le plus les vélos, on fait alors une moyenne sur tous les jours de la semaine pour chaque heure de la journée. (Chaque courbe correspond à une heure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3fce41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# On calcule la moyenne pour chaque heure sur tous les jours de la semaine\n",
    "mean_per_hour_per_day = loading.mean(axis = 0).to_numpy()\n",
    "mean_per_hour_per_day = mean_per_hour_per_day.reshape((24, 7))\n",
    "\n",
    "mean_per_hour = mean_per_hour_per_day.mean(axis=0)\n",
    "\n",
    "# --- #\n",
    "hours = [\"0h\", \"1h\", \"2h\",\"3h\", \"4h\", \"5h\", \"6h\", \"7h\", \"8h\", \"9h\", \"10h\", \"11h\", \"12h\", \"13h\", \"14h\", \"15h\", \"16h\", \"17h\", \"18h\", \"19h\", \"20h\", \"21h\", \"22h\", \"23h\"]\n",
    "plt.figure(figsize = (20,10))\n",
    "\n",
    "plt.plot(mean_per_hour_per_day.transpose())\n",
    "plt.plot(mean_per_hour, color = \"black\", linewidth = 3)\n",
    "\n",
    "plt.xlabel('Chargement horaire, moyenne de toutes les stations', fontsize = 15)\n",
    "plt.ylabel('Chargement', fontsize = 20)\n",
    "plt.legend(hours + ['hours'])\n",
    "plt.xticks(ticks = np.arange(0,7,4), labels=np.arange(0,7,4), fontsize = 15)\n",
    "  \n",
    "plt.tight_layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59419dbc-1047-4233-beb2-0a95dd763e7f",
   "metadata": {},
   "source": [
    "On peut voir que le chargement moyen est quasiment constant chaque jour, même le week-end, contrairement au graphe précédent où le chargement variait légèrement.\n",
    "\n",
    "On peut donc déjà supposer que l'heure a une plus forte influence sur le profil de chargement que le jour. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3689f6ec-0b59-47b5-b485-77f081e79473",
   "metadata": {},
   "source": [
    "On va maintenant regarder l'évolution du taux sur une station au hasard :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839b49e4-7872-4cb9-946e-80a62b3b22eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [15, 6]\n",
    "time_range = np.arange(1, 25)\n",
    "\n",
    "# on sélectionne aléatoirement un numéro d'un indice de ligne\n",
    "i = np.random.randint(1, 1190) \n",
    "\n",
    "df = loading.iloc[i]\n",
    "\n",
    "# Création d'une matrice de 24 lignes (une pour chaque heure)\n",
    "mean_per_hour_per_day = np.array(df).reshape(24, -1)\n",
    "\n",
    "# on calcul de la moyenne par heure\n",
    "mean_per_hour = np.mean(mean_per_hour_per_day, axis=1)\n",
    "\n",
    "# Conversion de la matrice en dataframe\n",
    "mean_per_hour_per_day = pd.DataFrame(mean_per_hour_per_day)\n",
    "\n",
    "# Renommage des colonnes avec les jours de la semaine\n",
    "mean_per_hour_per_day.columns = [\"Lundi\", \"Mardi\", \"Mercredi\", \"Jeudi\", \"Vendredi\", \"Samedi\", \"Dimanche\"]\n",
    "\n",
    "mean_per_hour_per_day['time_range'] = np.arange(1, 25)\n",
    "mean_per_hour_per_day = pd.melt(mean_per_hour_per_day, id_vars='time_range', var_name='Days')\n",
    "mean_per_hour = pd.DataFrame(mean_per_hour)\n",
    "\n",
    "mean_per_hour.columns = [\"Weekly\"]\n",
    "\n",
    "mean_per_hour['time_range'] = np.arange(1, 25)\n",
    "\n",
    "\n",
    "for day in mean_per_hour_per_day['Days'].unique():\n",
    "    plt.plot(mean_per_hour_per_day[mean_per_hour_per_day['Days'] == day]['time_range'], \n",
    "             mean_per_hour_per_day[mean_per_hour_per_day['Days'] == day]['value'], \n",
    "             label=day)\n",
    "\n",
    "plt.plot(mean_per_hour['time_range'], mean_per_hour['Weekly'], color='black', linewidth=3, label='Weekly')\n",
    "\n",
    "plt.title(coord.names[i])\n",
    "plt.xlabel(\"Heure de la journée\")\n",
    "plt.ylabel(\"Chargement moyen\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88ff12c-8872-4ed8-b011-f2a8b82c16a0",
   "metadata": {},
   "source": [
    "Regardons maintenant, quelle station est la plus chargée, en moyenne par semaine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048f16ac-737c-410a-bf85-bc79dabf818c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean=loading.mean(axis=1)\n",
    "i = mean.idxmin()\n",
    "print('Average fill rate :',mean[i])\n",
    "print(coord.loc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3630af5a-6889-4eaf-9d8e-a10bef74f2d3",
   "metadata": {},
   "source": [
    "Et de même la station la moins chargée, en moyenne par semaine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da5145b-1bb7-4f35-9d97-1b333d77e1e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean=loading.mean(axis=1)\n",
    "i = mean.idxmax()\n",
    "print('Average fill rate :',mean[i])\n",
    "print(coord.loc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01b8d1f-a99c-4a0a-a12e-3298b2a69bd8",
   "metadata": {},
   "source": [
    "On regarde le comportement moyen par heure (toutes les 4h) sur l'ensemble des stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc430967",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#on affiche le comportement moyen par heure (toutes les 4h)\n",
    "\n",
    "hours = [1, 5, 9, 13, 17, 21, 24]\n",
    "\n",
    "# Taille de la figure et nombre de sous-graphiques\n",
    "s = 10\n",
    "n = len(hours)\n",
    "num_rows = 2\n",
    "num_cols = (n + num_rows - 1) // num_rows\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(s * num_cols, s * num_rows))\n",
    "\n",
    "for i, h in enumerate(hours):\n",
    "    load_per_hour = np.mean(loading.iloc[:, h::24], axis=1)  # Calcul de la moyenne pour chaque heure sur tous les jours de la semaine\n",
    "    row = i // num_cols\n",
    "    col = i % num_cols\n",
    "    im = axs[row, col].scatter(coord.latitude, coord.longitude, c=load_per_hour, cmap=cm.plasma_r)\n",
    "    axs[row, col].set_title('Chargement à {} h'.format(h), fontsize=25)\n",
    "    plt.colorbar(im, ax=axs[row, col])\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set_xlabel('Latitude', fontsize=20)\n",
    "    ax.set_ylabel('Longitude', fontsize=20)\n",
    "    ax.tick_params(axis='x', labelsize=15)\n",
    "    ax.tick_params(axis='y', labelsize=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d45252-ea98-471b-aaf7-c97a4ae03712",
   "metadata": {},
   "source": [
    "Ces graphes nous permettent de voir que les zones des stations chargées varient fortement au cours de la journée. On peut supposer un déplacement des vélos vers le centre ville et les bords de Seine le matin entre 8h et 12h (qui pourraient correspondre aux zones de travail) car les stations sont en moyenne plus chargées, et elles semblent se vider entre 16h et 20h, pour se reremplir vers le Sud-Ouest et Sud-Est de Paris, qui pourraient correspondre aux zones d'habitations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dce456-f127-4f1f-a45e-1a7e1abb86dd",
   "metadata": {},
   "source": [
    "Regardons maintenant le comportement moyen des taux de chargements des stations à 18h pour chaque jour de la semaine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfa5634",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#on affiche le comportement des chargements des stations à 18h chaque jour\n",
    "loading_data = loading.to_numpy()\n",
    "\n",
    "h = 18\n",
    "hours = np.arange(h, 168, 24)\n",
    "\n",
    "load_per_hour = loading_data[:, hours]\n",
    "\n",
    "days = [\"Lundi\", \"Mardi\", \"Mercredi\", \"Jeudi\", \"Vendredi\", \"Samedi\", \"Dimanche\"]\n",
    "\n",
    "# --- #\n",
    "\n",
    "s, m = 10, 3\n",
    "k = 1 + len(days)//m\n",
    "\n",
    "fig = plt.figure(figsize=(s+1, s))\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=.3, wspace=.25)\n",
    "\n",
    "for (i,d) in enumerate(days):\n",
    "    ax = fig.add_subplot(k, m, i+1)\n",
    "    im = ax.scatter(coord.latitude, coord.longitude, c = load_per_hour[:,i], cmap = 'viridis')\n",
    "    plt.colorbar(im)\n",
    "    \n",
    "    ax.set_title('Stations de chargement - ' + d + ' {} h'.format(h))\n",
    "    ax.set_xlabel('Latitude')\n",
    "    ax.set_ylabel('Longitude')\n",
    "    ax.tick_params(axis='x')\n",
    "    ax.tick_params(axis='y')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e4d136-871f-4648-af18-ad65a4cfbdc0",
   "metadata": {},
   "source": [
    "En comparant le chargement moyen par jour et non plus par heures, on voit que celui-ci semble beaucoup moins varier. L'influence du jour semble moindre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6499c24f-0998-4184-83d7-9fac75849c25",
   "metadata": {},
   "source": [
    "On fait ici la même chose que précédemment mais on projette les stations sur la carte de Paris, pour avoir une idée plus visuelle de leur localisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63832c62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Position = np.array(coord)[:,0:2]\n",
    "\n",
    "#graphe à 1h\n",
    "a1 = np.arange(1,168,24, dtype=int)\n",
    "data1h = np.mean(np.array(loading)[:,a1],axis=1)\n",
    "\n",
    "fig1 = px.scatter_mapbox(data1h, Position[:,1], Position[:,0], color=data1h, color_continuous_scale = px.colors.sequential.Plasma_r, \n",
    "                        size_max=15, zoom=10,mapbox_style=\"carto-positron\", opacity = .9,\n",
    "                        title = 'Chargement à 1h')\n",
    "fig1.show()\n",
    "\n",
    "a5 = np.arange(5,168,24, dtype=int)\n",
    "data5h = np.mean(np.array(loading)[:,a5],axis=1)\n",
    "\n",
    "fig5 = px.scatter_mapbox(data5h, Position[:,1], Position[:,0], color=data5h, color_continuous_scale = px.colors.sequential.Plasma_r, \n",
    "                        size_max=15, zoom=10,mapbox_style=\"carto-positron\", opacity = .9,\n",
    "                        title = 'Chargement à 5h')\n",
    "fig5.show()\n",
    "\n",
    "a9 = np.arange(9,168,24, dtype=int)\n",
    "data9h = np.mean(np.array(loading)[:,a9],axis=1)\n",
    "\n",
    "fig9 = px.scatter_mapbox(data9h, Position[:,1], Position[:,0], color=data9h, color_continuous_scale = px.colors.sequential.Plasma_r, \n",
    "                        size_max=15, zoom=10, mapbox_style=\"carto-positron\", opacity = .9,\n",
    "                        title = 'Chargement à 9h')\n",
    "fig9.show()\n",
    "\n",
    "a13 =np.arange(13,168,24, dtype=int)\n",
    "data13h = np.mean(np.array(loading)[:,a13],axis=1)\n",
    "\n",
    "fig13 = px.scatter_mapbox(data13h, Position[:,1], Position[:,0], color=data13h, color_continuous_scale=px.colors.sequential.Plasma_r, \n",
    "                          size_max=15, zoom=10,mapbox_style=\"carto-positron\", \n",
    "                         title = 'Chargement à 13h')\n",
    "fig13.show()\n",
    "\n",
    "a17 =np.arange(17,168,24, dtype=int)\n",
    "data17h = np.mean(np.array(loading)[:,a17],axis=1)\n",
    "\n",
    "fig17 = px.scatter_mapbox(data17h, Position[:,1], Position[:,0], color=data17h, color_continuous_scale=px.colors.sequential.Plasma_r, \n",
    "                          size_max=15, zoom=10,mapbox_style=\"carto-positron\",\n",
    "                         title = 'Chargement à 17h')\n",
    "fig17.show()\n",
    "\n",
    "\n",
    "a21 =np.arange(21,168,24, dtype=int)\n",
    "data21h = np.mean(np.array(loading)[:,a21],axis=1)\n",
    "\n",
    "fig21= px.scatter_mapbox(data21h, Position[:,1], Position[:,0], color=data21h, color_continuous_scale=px.colors.sequential.Plasma_r, \n",
    "                          size_max=15, zoom=10,mapbox_style=\"carto-positron\",\n",
    "                        title = 'Chargement à 21h')\n",
    "fig21.show()\n",
    "\n",
    "\n",
    "\n",
    "a24 =np.arange(24,168,24, dtype=int)\n",
    "data24h = np.mean(np.array(loading)[:,a24],axis=1)\n",
    "\n",
    "fig24 = px.scatter_mapbox(data24h, Position[:,1], Position[:,0], color=data24h, color_continuous_scale=px.colors.sequential.Plasma_r, \n",
    "                          size_max=15, zoom=10,mapbox_style=\"carto-positron\",\n",
    "                         title = 'Chargement à 24h')\n",
    "fig24.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95df6496",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from matplotlib import colors\n",
    "!pip install yellowbrick\n",
    "from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0928e829",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Etude sur le jeu de données complet "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1fa365",
   "metadata": {},
   "source": [
    "### 3.1. ACP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305d8551-3ce6-4293-b284-e2bcdc0e4493",
   "metadata": {},
   "source": [
    "Notre étude porte sur un grand jeu de données, nous voudrions trouver un moyen de réduire la dimension de notre jeu de données. Pour ce faire, nous décidons de faire une ACP (Analyse en Composantes Principales) sur notre jeu de donneés afin de réduire un maximum les dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0ce0e0",
   "metadata": {},
   "source": [
    "Pour cela, nous commençons par afficher les boxplots des variables quantitatives sur la même échelle, pour voir s'il est intéressant de standardiser nos données. En effet, si nos données ne sont pas exprimées dans la même échelle/unité cela peut influencer l'importance qu'a une variable sur notre ACP. Ici toutes les données sont comprises entre 0 et 1. Il n'est donc pas nécessaire de standardiser les données. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe403eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Affichage en boxplot des variables qualitatives sur la mëme échelle\n",
    "plt.figure(figsize=(5,5))\n",
    "loading.boxplot()\n",
    "plt.title('Boxplot')\n",
    "plt.xticks(rotation=-90)\n",
    "plt.xlabel('Colonne')\n",
    "plt.ylabel('Valeurs')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0301093",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "loading_pca = pca.fit_transform(loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f601dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#On affiche la variance expliquée par les composantes de l'ACP\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.title('Variance cumulée expliquée en fonction de la dimension de l espace de l`ACP')\n",
    "plt.xlabel('Nombre de composantes dans l ACP')\n",
    "plt.ylabel('Variance cumulée expliquée')\n",
    "\n",
    "#On regarde le nombre de composantes exacts qu'il nous faut garder afin d'avoir un pourcentage expliqué égal à 80%\n",
    "pca = PCA(0.80).fit(loading) \n",
    "\n",
    "# Affichage du nombre de composantes qu'on garde pour la ACP\n",
    "pca.n_components_ \n",
    "print(f\"on garde {pca.n_components_} composants pour le PCA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb928f5e",
   "metadata": {},
   "source": [
    "La fonction nous dit qu'il faut garder 7 composantes pour expliquer 80% de la variance, cependant cela semble beaucoup , en effet quand on regarde l'histogramme ci-dessous des pourcentages de représentation de chaque composante, on voit qu'après la 5ème composante celles-ci n'explique que très peu la variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f799b22c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Réalisation de l'ACP à 5 composantes\n",
    "pca = PCA(n_components=7)\n",
    "\n",
    "loading_pca = pca.fit_transform(loading) \n",
    "\n",
    "print(100*pca.explained_variance_ratio_)\n",
    "\n",
    "#Affichage et vérification de la dimension du jeu de données avant et après ACP\n",
    "print('--- PCA ---')\n",
    "print('Dimension initiale :' , loading.shape)\n",
    "print('Dimension après projection:', loading_pca.shape)\n",
    "\n",
    "print('')\n",
    "\n",
    "print('--- Variance expliquée  ---')\n",
    "print('Composante 1:', round(pca.explained_variance_[0],2), 'i.e.', round(100*pca.explained_variance_ratio_[0],2), '% de la variance totale')\n",
    "print('Composante 2:', round(pca.explained_variance_[1],2), 'i.e.', round(100*pca.explained_variance_ratio_[1],2), '% de la variance totale')\n",
    "print('Composante 3:', round(pca.explained_variance_[2],2), 'i.e.', round(100*pca.explained_variance_ratio_[2],2), '% de la variance totale')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6feabeac",
   "metadata": {},
   "source": [
    "On affiche le barplot représentant la proportion qu'explique chaque variable au niveau de la variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb00427b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Affichage du bar plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=[f\"PC{i+1}\" for i in range(len(pca.explained_variance_ratio_))], y=pca.explained_variance_ratio_ * 100)\n",
    "plt.xlabel(\"Composantes Principales\")\n",
    "plt.ylabel(\"Pourcentage de Variance Expliquée\")\n",
    "plt.title(\"Proportion de Variance Expliquée par Chaque Composante Principale\")\n",
    "plt.ylim(0, 40) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2240b684-4a46-47cd-9239-292ba07672c0",
   "metadata": {},
   "source": [
    "D'où notre choix de garder seulement 5 composantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f38597c-711c-4665-9711-e9c27e65d5a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Réalisation de l'ACP à 5 composantes\n",
    "pca = PCA(n_components=5)\n",
    "loading_pca = pca.fit_transform(loading) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93854cbb-7655-44ec-9787-1eee22a5d7d7",
   "metadata": {},
   "source": [
    "Voici l'histogramme et les boxplots représentant le pourcentage de variance expliquée par chaque composante principale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71a6237-ee91-4657-b6d2-55161c790f2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Affichage des bar plot de la proportion d'explication de la variance par chaque composante de l'ACP\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=[f\"PC{i+1}\" for i in range(len(pca.explained_variance_ratio_))], y=pca.explained_variance_ratio_ * 100)\n",
    "plt.xlabel(\"Composantes Principales\")\n",
    "plt.ylabel(\"Pourcentage de Variance Expliquée\")\n",
    "plt.title(\"Proportion de Variance Expliquée par chaque composante principale\")\n",
    "plt.ylim(0, 40)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8ece4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Affichage des boxplots des composantes de l'ACP\n",
    "box = plt.boxplot(loading_pca[:,:10], patch_artist=True)\n",
    "plt.setp(box[\"boxes\"], facecolor=\"coral\", alpha=.5)\n",
    "plt.title(\"Box plots of the first ten principal components\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814df8f0-e4ee-45fc-8d55-4545ba511594",
   "metadata": {},
   "source": [
    "Une fois notre ACP réalisée, on projette nos données dans l'espace d'ACP. \n",
    "\n",
    "Voici les graphes de projections des données sur les axes des deux composantes principales de l'ACP, qui expliquent le plus de variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e98abff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coord1 = pca.components_[0] * np.sqrt(pca.explained_variance_[0])\n",
    "coord2 = pca.components_[1] * np.sqrt(pca.explained_variance_[1])\n",
    "\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "arrow_length_factor = 3\n",
    "# Facteur de longueur des flèches\n",
    "\n",
    "for i, j, nom in zip(coord1, coord2, loading.columns):\n",
    "    plt.text(i*arrow_length_factor, j*arrow_length_factor, nom, fontsize=10)\n",
    "    plt.arrow(0, 0, i* arrow_length_factor, j* arrow_length_factor, color = 'purple', alpha=0.7, width = 0.001)\n",
    "\n",
    "plt.axis((-1, 1, -1, 1))\n",
    "plt.gcf().gca().add_artist(plt.Circle((0, 0), radius = 1, color = 'cornflowerblue', fill = False))\n",
    "\n",
    "plt.title('Variables factor map - PCA')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbb7aab",
   "metadata": {},
   "source": [
    "Et le graphe sur les axes 1 et 3 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4909e668",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coord1 = pca.components_[0] * np.sqrt(pca.explained_variance_[0])\n",
    "coord2 = pca.components_[2] * np.sqrt(pca.explained_variance_[1])\n",
    "\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "arrow_length_factor = 3\n",
    "# Facteur de longueur des flèches\n",
    "\n",
    "for i, j, nom in zip(coord1, coord2, loading.columns):\n",
    "    plt.text(i*arrow_length_factor, j*arrow_length_factor, nom, fontsize=10)\n",
    "    plt.arrow(0, 0, i*arrow_length_factor, j*arrow_length_factor, color = 'purple', alpha=0.7, width = 0.001)\n",
    "\n",
    "plt.axis((-1, 1, -1, 1))\n",
    "plt.gcf().gca().add_artist(plt.Circle((0, 0), radius = 1, color = 'cornflowerblue', fill = False))\n",
    "\n",
    "plt.title('Variables factor map - PCA')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 3')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0005cef",
   "metadata": {},
   "source": [
    "Les projections dans les espaces d'ACP peuvent nous amener à faire les hypothèses suivantes : \n",
    "- la composante 1 semble correspondre au chargement moyen des stations. \n",
    "- Il est compliqué de trouver une interprétation à la composante 2 car la grande quantité de données nous ne permet pas d'avoir un rendu visuel. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742cf69a-b9e1-4fde-a152-a68a3b3ca760",
   "metadata": {},
   "source": [
    "#### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8021307-1c0a-473e-88d0-6d210daf8a8c",
   "metadata": {},
   "source": [
    "Dans cette partie nous allons tenter de déterminer des caractéristiques communes à nos données. Grâce à ces points communs, nous allons pouvoir classifier les données et ainsi les diviser en sous-groupes. Cette étape permet d'interpréter au mieux nos données. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b319ea62",
   "metadata": {},
   "source": [
    "#### 3.1.1. Méthode de clustering avec k-means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c228eb40-169f-4cfd-8f3a-383e818426c6",
   "metadata": {},
   "source": [
    "L'algorithme K-Means est une technique de classification non-supervisée des données. Il cherche à minimiser les distances entre les observations et les centres des clusters auxquels elles appartiennent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0bd3e1-1f2b-4638-a221-1f56c890f970",
   "metadata": {},
   "source": [
    "Cette fonction sera utilisée dans la suite de l'analyse pour faire correspondre les clusters lors de l'analyse sur les données réduits et sur les données complètes pour pouvoir ainsi comparer les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48be492",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def matchClasses(classif1, classif2):\n",
    "    cm = confusion_matrix(classif1, classif2)\n",
    "    K = cm.shape[0]\n",
    "    a, b = np.zeros(K), np.zeros(K)\n",
    "    for j in range(K):\n",
    "        for i in range(K):\n",
    "            if (a[j] < cm[i,j]):\n",
    "                a[j] = cm[i,j]\n",
    "                b[j] = i \n",
    "    a = a.astype(int)\n",
    "    b = b.astype(int)\n",
    "                                             \n",
    "    print (\"\")\n",
    "    print (\"Classes size:\", a)\n",
    "    print (\"Class (in the classif1 numbering):\", b)\n",
    "    print (\"\")\n",
    "    \n",
    "    table = cm.copy()\n",
    "    for i in range(K):\n",
    "        table[:,b[i]] = cm[:,i]   \n",
    "        \n",
    "    clusters = classif2.copy()\n",
    "    n = classif2.shape[0]\n",
    "    for i in range(n):\n",
    "        for j in range(K):\n",
    "            if (classif2[i] == j):\n",
    "                clusters[i] = b[j]\n",
    "        \n",
    "    return table, clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b178b965-6560-4014-a8f4-678f28696535",
   "metadata": {},
   "source": [
    "Tout d'abord, on va effectuer l'algorithme K-Means sur le jeu de données de base 'loading' et voir si on peut en tirer quelques interprétations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d4659a",
   "metadata": {},
   "source": [
    "On va déterminer le nombre de clusters optimal grace à la méthode du coude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516e542a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inertia = []\n",
    "for k in range(1, 15):\n",
    "    kmeans = KMeans(n_clusters=k, init='random', n_init='auto', max_iter=100, random_state=42)\n",
    "    kmeans.fit(loading)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "inertia = np.array(inertia)\n",
    "\n",
    "\n",
    "plt.scatter(range(2, 15), inertia[1:])\n",
    "plt.xlabel('nombre de clusters', fontsize = 15)\n",
    "plt.ylabel('inertie', fontsize = 15)\n",
    "plt.title(\"Graphe du coude\", fontsize = 15)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- #\n",
    "\n",
    "\n",
    "# avec yellowbrick\n",
    "\n",
    "kmeans = KMeans(init='random', n_init='auto', max_iter=100, random_state=42)\n",
    "visualizer = KElbowVisualizer(kmeans, k=(1,12))\n",
    "\n",
    "visualizer.fit(loading)   \n",
    "visualizer.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab35cb93",
   "metadata": {},
   "source": [
    "Pour analyser ces graphes, on cherche le coude c'est à dire le moment où lorsqu'on va enlève un cluster il y aura une grande augmentation d'inertie, et lorsqu'on en ajoute un, une faible diminution de l'inertie. Dans le premier graphe, on peut observer une différence de tendance entre 2 et le 4. Pour le deuxième graphe, le coude est annoncé à 4. Avec ces graphes on choisirait donc un nombre de clusters de 4.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24080f0",
   "metadata": {},
   "source": [
    "Nous allons maintenant utiliser la méthode \"silhouette score\" pour valider notre choix de clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337a49b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(15,8))\n",
    "\n",
    "for k in range(2, 6):\n",
    "    kmeans = KMeans(n_clusters=k, init='random', n_init='auto', max_iter=100, random_state=42)\n",
    "    q, mod = divmod(k, 2) \n",
    "    visualizer = SilhouetteVisualizer(kmeans, colors='yellowbrick', ax=ax[q-1][mod])\n",
    "    visualizer.fit(loading)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3946350",
   "metadata": {},
   "source": [
    "Pour choisir le nombre de clusters le plus adapté il faut trouver un équilibre entre plusieurs aspects. Tout d'abord, il faut que chaque pic dépasse le trait rouge, alors, les données sont adaptées au nombre de classes. Aussi, il faudrait dans l'idéal que chaque pic ait la même épaisseur. Enfin, il faut qu'il y ait le moins de valeurs négatives possibles, elles correspondent au nombre de variables mal classées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243492c9-c600-4975-9f82-81c3caac8205",
   "metadata": {},
   "source": [
    "Dans notre cas, le score silouhette pour 4 clusters n'a pas énormément de valeurs négatives et les bandes dépassent le trait. On pourrait aussi choisir de prendre 3 clusters car les résultats sont bons. Mais pour une meilleure interprétation on choisit d'en prendre 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f5125f-c48d-4a27-937e-0e4b503bb654",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "K = 4\n",
    "kmeans = KMeans(n_clusters=K, init='random', n_init='auto', random_state=0)\n",
    "#on fixe le nombre de clusters à 4 pour la suite de l'analyse\n",
    "clusters = kmeans.fit_predict(loading)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3fad5a",
   "metadata": {},
   "source": [
    "Ci-dessous on observe l'histogramme des classifications formées avec le nombre de clusters qui nous avons choisi (ici 4). Cet affichage va nous permettre de voir la répartition des variables dans les clusters et ainsi savoir si certains clusters sont plus importants que d'autres. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd503ab2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('Set3',K)\n",
    "plt.bar(*np.unique(clusters, return_counts=True), color=cmap.colors)\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e6ad21",
   "metadata": {},
   "source": [
    "On constate que les variables sont réparties de manière assez hétérogène. La majorité des valeurs se trouvent dans le cluster 4 et le reste se trouve assez équitablement réparti dans les clusters 1, 2 et 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f40afe-b67f-4fb5-8cd8-3afd4564f1f7",
   "metadata": {},
   "source": [
    "Avant de tirer des conclusions des analyses qui vont suivre, il faut vérifier que la variance intra-classe de chaque clusters.En effet, cela permet d'évaluer l'homogénéité des groupes et d'être sur que tous les éléments d'un même groupe ont un comportement similaire. Si la variance intraclasse est faible, alors on est assuré de la rigueur de nos analyses. <br> On affiche pour cela la variance intraclasse associée à chaque cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baf8ec4-20bb-4dbc-bf2b-831dbc37ea9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# distance de chaque point de données à son centre de cluster\n",
    "distances = kmeans.transform(loading)\n",
    "\n",
    "#variance intraclasse pour chaque cluster\n",
    "variances = []\n",
    "for cluster in range(kmeans.n_clusters):\n",
    "    cluster_distances = distances[kmeans.labels_ == cluster, cluster]\n",
    "    variance = np.var(cluster_distances)\n",
    "    variances.append(variance)\n",
    "\n",
    "# Affichage\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(range(kmeans.n_clusters), variances, color='skyblue')\n",
    "plt.xlabel('Clusters')\n",
    "plt.ylabel('Variance intra-classe')\n",
    "plt.title('Variance intra-classe par cluster')\n",
    "plt.xticks(range(kmeans.n_clusters), [f'Cluster {i+1}' for i in range(kmeans.n_clusters)])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745b9d48-e6fc-49cc-b33e-382aa48d83b4",
   "metadata": {},
   "source": [
    "On voit que la variance des clusters est assez petite, et de taille équivalente pour chacun des clusters, le profil de chargement des stations dans chaque cluster se ressemble donc. <br>\n",
    "On affiche maintenant les boxplots qui illustre la répartition des distances de chaque point au centre de son cluster. Nous allons vérifier que cette distribution est dans une fenêtre assez réduite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4f54e5-480b-44e3-9e81-ba32fdb6181e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculer les distances de chaque point de données à son centre de cluster\n",
    "distances = kmeans.transform(loading)\n",
    "\n",
    "# Créer une liste de distances pour chaque cluster\n",
    "distances_per_cluster = [[] for _ in range(kmeans.n_clusters)]\n",
    "for cluster in range(kmeans.n_clusters):\n",
    "    cluster_distances = distances[kmeans.labels_ == cluster, cluster]\n",
    "    distances_per_cluster[cluster] = cluster_distances\n",
    "\n",
    "# Plotter les boxplots\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(distances_per_cluster, patch_artist=True, labels=[f'Cluster {i+1}' for i in range(kmeans.n_clusters)])\n",
    "plt.xlabel('Clusters')\n",
    "plt.ylabel('Distance au centre de cluster')\n",
    "plt.title('Distribution des distances au centre de cluster')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f42f777-eb13-42ff-b688-b184e8cb8a53",
   "metadata": {},
   "source": [
    "Les boxplots associés à chaque clusters ne sont pas très longs, cela est une autre façon d'illustrer les résultats précédents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1566db-a7e2-46fd-965d-d5ac7d125345",
   "metadata": {},
   "source": [
    "On va afficher maintenant le chargement moyen des stations par clusters au cours de la semaine. Cela va peut-être nous permettre de visualiser des tendances communes entre les éléments d'un même cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dcbef3-eb7d-498e-bad9-d86dad24553a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loading_sub = loading.iloc[:,:]\n",
    "loading_sub['cluster']=clusters\n",
    "mean_loading=loading_sub.groupby('cluster').mean()\n",
    "mean_loading.head()\n",
    "\n",
    "col = ['#800080','#008080','#FFFF00','#FF69B4']\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Affichage des 4 lignes sur le même graphique\n",
    "for i in range(4):\n",
    "    ax.plot(mean_loading.columns, mean_loading.iloc[i], label=f'Cluster {i+1}', color=col[i])\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Moyenne des chargements par cluster')\n",
    "plt.xlabel('Temps en heures')\n",
    "plt.ylabel('Moyenne des loading')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e56568-f984-4054-ad11-93e0c45f060e",
   "metadata": {},
   "source": [
    "Ce graphe représente le chargement moyen des stations en fonction de l'heure et chaque courbe représente un cluster. \n",
    "On peut analyser 4 types de comportements différents. \n",
    "Un cluster se charge en soirée et se vide le matin avec un chargement qui varie beaucoup.C'est des stations qui pourraient correspondre aux zones d'habitation, où les gens rentrent du travail et chargent les stations et les vident en partant au travail le matin. \n",
    "\n",
    "Ensuite, un autre à un comportement inverse au précédent, il correspond aux stations qui se chargent en journée, quand les gens arrivent au travail et se vide quand les gens rentrent chez eux. Le week-end, les variations de chargement de ce cluster sont moins importantes car tous les gens ne se rendent pas dans ces lieux. \n",
    "\n",
    "Un autre cluster se charge également en journée mais les stations sont plus vides en moyenne et le chargement varie moins. \n",
    "\n",
    "Enfin, à l'inverse du précédent, le dernier cluster se charge en soirée avec des stations plus chargées en moyenne mais avec aussi un chargement qui varie moins. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f64c110-9458-47da-aa14-2da9d2ab9b4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "On va maintenant tenter de faire un lien entre la variable 'Hill' est les clusters formés par K-Means. Pour ce faire, on dresse une table croisée qui va mettre en lien 'Hill' et les clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e49a982-946c-4149-8d83-53e67b970eb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tbl1 = pd.crosstab(clusters, coord['bonus'])\n",
    "\n",
    "#on affiche la mosaïque :\n",
    "tbl1.index = ['Cluster_1', 'Cluster_2', 'Cluster_3', 'Cluster_4'] \n",
    "tbl1.columns = ['Pas colline', 'Colline']  \n",
    "\n",
    "sns.heatmap(tbl1, cmap='coolwarm', annot=True, fmt=\"d\")\n",
    "plt.title(\"Stations en altitude en fonction du clusters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b81baa9-d24c-4718-a3bc-1b15d6cd4566",
   "metadata": {},
   "source": [
    "On voit que 119 stations classées dans un cluster sont localisées sur des collines alors que les 8 restantes sont partagées entres les 3 autres clusters. Ce cluster semble être le plus représentatif des stations en altitude, d'après le graphe des moyennes, il représente aussi les stations aux taux souvent bas voir très bas, ce qui signifie qu'il n'y a pas beaucoup de vélo dans la station, les vélos sont donc empruntés mais jamais ramenés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6871b59f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Etude sur loading_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8608465-5cf0-4adf-a0a9-8f926262b1fb",
   "metadata": {},
   "source": [
    "Maintenant, on va effectuer l'algorithme K-Means à nouveau mais cette fois-ci, sur le jeu de données réduit par l'ACP. Cela va permettre de voir si les données réduites représentent bien le jeu de données complet. On cherche entre autre à voir si la classification réalisée sur le jeu de données complet et la même sur celui réduit, si c'est le cas cela nous permettra de simplifier les calculs des algorithmes suivants en travaillant sur le jeu de données réduit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740c0e18-55ad-4d84-80bc-b1a7b8a6a9b1",
   "metadata": {},
   "source": [
    "On va déterminer le nombre de clusters optimal grace à la méthode du coude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1f4ac5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inertia = []\n",
    "for k in range(1, 15):\n",
    "    kmeans_pca = KMeans(n_clusters=k, init='random', n_init='auto', max_iter=100, random_state=42)\n",
    "    kmeans_pca.fit(loading_pca)\n",
    "    inertia.append(kmeans_pca.inertia_)\n",
    "inertia = np.array(inertia)\n",
    "\n",
    "\n",
    "plt.scatter(range(2, 15), inertia[1:])\n",
    "plt.xlabel('nombre de clusters', fontsize = 15)\n",
    "plt.ylabel('inertie', fontsize = 15)\n",
    "plt.title(\"Graphe du coude\", fontsize = 15)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- #\n",
    "\n",
    "\n",
    "# Using yellowbrick\n",
    "\n",
    "kmeans_pca = KMeans(init='random', n_init='auto', max_iter=100, random_state=42)\n",
    "visualizer = KElbowVisualizer(kmeans_pca, k=(1,12))\n",
    "\n",
    "visualizer.fit(loading_pca)    # Fit the data to the visualizer\n",
    "visualizer.show()    # Finalize and render the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f748ad",
   "metadata": {},
   "source": [
    "D'après la méthode du coude on peut dire que le nombre de clusters le plus adapté avec K-means est de 4. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d705e3bf",
   "metadata": {},
   "source": [
    "Nous allons utiliser la méthode \"silouhette score\" pour valider le résultat précedent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5dd762",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(15,8))\n",
    "\n",
    "for k in range(2, 6):\n",
    "    kmeans_pca = KMeans(n_clusters=k, init='random', n_init='auto', max_iter=100, random_state=42)\n",
    "    q, mod = divmod(k, 2) \n",
    "    visualizer = SilhouetteVisualizer(kmeans_pca, colors='yellowbrick', ax=ax[q-1][mod])\n",
    "    visualizer.fit(loading_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401e7a0e-00f0-4807-bf21-294bfcd32318",
   "metadata": {},
   "source": [
    "On peut voir que le graphe pour 4 clusters est très correct : peu de valeurs négatives et des clusters qui dépassent tous la moyenne. On aurait aussi pu choisir 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d810bd8-ea2c-4d36-9d26-973ff25d00ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "K = 4\n",
    "kmeans_pca = KMeans(n_clusters=K, init='random', n_init='auto', random_state=0)\n",
    "clusters_pca = kmeans_pca.fit_predict(loading_pca)\n",
    "#On fixe le nombre de clusters à 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e9dfb1",
   "metadata": {},
   "source": [
    "Regardons maintenant la répartition des données au sein des clusters. Si on choisit un nombre de clusters égal à 4, voici l'histogramme des données associé :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c267bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('Set3',K)\n",
    "plt.bar(*np.unique(clusters, return_counts=True), color=cmap.colors)\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed237728-84bb-47b4-b1f3-dd593ee45a11",
   "metadata": {},
   "source": [
    "La répartition des valeurs est équivalente à celle pour l'étude de loading complet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5f4446-2bf2-463b-afdc-e82921c7752e",
   "metadata": {},
   "source": [
    "On visualise ici la répartition des valeurs dans le plan de l'ACP (dimention 1 et 2) pour voir comment se comporte les clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4c8f9f-1f01-463b-a6cd-e75616ca0d88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Définition des couleurs des clusters\n",
    "colors = ['#800080','#008080','#FFFF00','#2E4E7E']\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "# Tracé du nuage de points des clusters dans l'espace d'ACP\n",
    "scatter = plt.scatter(loading_pca[:, 0], loading_pca[:, 1], c=clusters_pca, cmap='viridis', s=50, alpha=0.5)\n",
    "\n",
    "# Définition des étiquettes de légende pour chaque cluster\n",
    "legend_labels = ['Cluster 1', 'Cluster 2', 'Cluster 3', 'Cluster 4']\n",
    "\n",
    "# Création des marqueurs de légende avec les couleurs correspondantes\n",
    "legend_markers = [plt.Line2D([0], [0], linestyle='none', marker='o', color=color, markersize=10) for color in colors]\n",
    "\n",
    "# Affichage de la légende avec les marqueurs et les étiquettes définis\n",
    "plt.legend(legend_markers, legend_labels, loc='lower right')\n",
    "\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('Clusters dans le plan de l\\'ACP')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ec976b-6b67-48f8-9cfb-c3ecbb90924d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Les variables en dim1 et dim2 sont bien réparties et les clusters ne se chevauchent pas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3864e8-ffdf-45be-b409-2711df735743",
   "metadata": {},
   "source": [
    "Avant de tirer des conclusions des analyses qui vont suivre, il faut vérifier que la variance intra-classe de chaque clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa376966-e78d-4920-9157-4bdad400f590",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# distance de chaque point de données à son centre de cluster\n",
    "distances = kmeans_pca.transform(loading_pca)\n",
    "\n",
    "#variance intraclasse pour chaque cluster\n",
    "variances = []\n",
    "for cluster in range(kmeans_pca.n_clusters):\n",
    "    cluster_distances = distances[kmeans_pca.labels_ == cluster, cluster]\n",
    "    variance = np.var(cluster_distances)\n",
    "    variances.append(variance)\n",
    "\n",
    "# Affichage\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(range(kmeans_pca.n_clusters), variances, color='skyblue')\n",
    "plt.xlabel('Clusters')\n",
    "plt.ylabel('Variance intra-classe')\n",
    "plt.title('Variance intra-classe par cluster')\n",
    "plt.xticks(range(kmeans_pca.n_clusters), [f'Cluster {i+1}' for i in range(kmeans_pca.n_clusters)])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9004cd5e-576a-4c7f-933b-b63c5c6ad04e",
   "metadata": {},
   "source": [
    "Les variances sont assez faibles donc on peut faire des analyses sur ces données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcc53f1-5365-4024-8c94-6810501f2fc1",
   "metadata": {},
   "source": [
    "On va maintenant tenter de faire un lien entre la variable 'Hill' est les clusters formés par K-Means. Pour ce faire, on dresse une table croisée qui va mettre en lien 'Hill' et les clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaa530c-113a-4e2f-9a3d-07829b4ff74f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tbl1_2 = pd.crosstab(clusters_pca, coord['bonus'])\n",
    "\n",
    "#on affiche la mosaïque :\n",
    "tbl1_2.index = ['Cluster_1', 'Cluster_2', 'Cluster_3', 'Cluster_4'] \n",
    "tbl1_2.columns = ['Pas colline', 'Colline']  \n",
    "\n",
    "sns.heatmap(tbl1_2, cmap='coolwarm', annot=True, fmt=\"d\")\n",
    "plt.title(\"Stations en altitude en fonction du clusters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccf172d-61bb-46b2-8267-7d7932d50bd4",
   "metadata": {},
   "source": [
    "Ici, on voit que les stations en altitude sont globalement regroupées dans un cluster. En effet, on remarque que dans la ligne 1 (les stations en altitudes), 118 variables sont dans le même cluster alors que les 8 autres variables sont divisées entre les clusters. Ainsi, ce cluster de cette classification ressemble au cluster de la classification sur le jeu de données complet où les stations en altitude étaient le plus présente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6c0c82-80f1-4a1e-a5a2-f4af10abbfcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loading_sub2 = loading.iloc[:,:]\n",
    "loading_sub2['cluster']=clusters_pca\n",
    "mean_loading2=loading_sub2.groupby('cluster').mean()\n",
    "mean_loading2.head()\n",
    "\n",
    "col = ['#800080','#008080','#FFFF00', '#FF69B4']\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Affichage des 4 lignes sur le même graphique\n",
    "for i in range(4):\n",
    "    ax.plot(mean_loading2.columns, mean_loading2.iloc[i], label=f'Cluster {i+1}', color=col[i])\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Moyenne des chargements par cluster')\n",
    "plt.xlabel('Temps en heures')\n",
    "plt.ylabel('Moyenne des loading')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0961804-2758-4387-8fab-8a920f6582b2",
   "metadata": {},
   "source": [
    "Un cluster se charge en soirée et se vide le matin avec un chargement qui varie beaucoup.\n",
    "Ensuite, un autre à un comportement inverse au précédent, il correspond aux stations qui se chargent en journée, et se vide quand les gens rentrent chez eux. Le week-end, les variations de chargement de ce cluster sont moins importantes. \n",
    "\n",
    "Un autre cluster se charge également en journée mais les stations sont plus vides en moyenne et le chargement varie moins. \n",
    "\n",
    "Enfin, à l'inverse du précédent, le dernier cluster se charge en soirée avec des stations plus chargées en moyenne mais avec aussi un chargement qui varie moins. \n",
    "\n",
    "Finalement, les profils de chargement des clusters se ressemblent fortement entre les données pca et non transformées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e83ee1-f576-4120-a0c4-010fa76803f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Comparaison des classification avec scatterplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25516a72",
   "metadata": {},
   "source": [
    "Comparaison des deux classifications grâce à un scatterplot pour voir le nombre de valeurs qui correspondent dans le cas normal et le cas réduit, afin de voir si il est vraiment utile de faire son analyse sur l'ACP ou non ? :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7098905f-894b-4f86-aba0-b9bef5f9e5f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Position = np.array(coord)[:,0:2]\n",
    "\n",
    "#nuage de points pour loading entier \n",
    "f1 = px.scatter_mapbox(clusters, Position[:,1], Position[:,0], color=clusters, color_continuous_scale=[(0, '#800080'), (0.5, '#008080'), (1, '#FFFF00')], \n",
    "                        size_max=15, zoom=10,mapbox_style=\"carto-positron\", opacity = .9,\n",
    "                        title = 'clusters données complètes')\n",
    "\n",
    "f1.show()\n",
    "\n",
    "f2 = px.scatter_mapbox(clusters_pca, Position[:,1], Position[:,0], color=clusters_pca, color_continuous_scale =[(0, '#800080'), (0.5, '#008080'), (1, '#FFFF00')], \n",
    "                        size_max=15, zoom=10,mapbox_style=\"carto-positron\", opacity = .9,\n",
    "                        title = 'clusters données pca')\n",
    "f2.show()\n",
    "\n",
    "\n",
    "\n",
    "#reclassement des clusters pour matcher les couleurs\n",
    "cm1, clusters_pca_sorted = matchClasses(clusters, clusters_pca)\n",
    "\n",
    "#quels sont les pints identiques ?\n",
    "points_diff = clusters != clusters_pca_sorted\n",
    "\n",
    "num_diff_points = np.sum(points_diff)\n",
    "\n",
    "pourcentage_reussite = (1- num_diff_points / len(clusters)) * 100\n",
    "\n",
    "print(f\"Nombre de points différents : {num_diff_points} sur {len(clusters)}\")\n",
    "print(f\"Pourcentage de réussite : {pourcentage_reussite:.2f}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588d29d4-8f42-4a94-ab86-1eab8db14e02",
   "metadata": {},
   "source": [
    "Le pourcentage de réussité est vraiment très important, seulement 6 points ne correspondent pas, les données matchent bien. Vérifions cela grâce à la matrice de confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1badfd37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay(confusion_matrix(clusters, clusters_pca)).plot()\n",
    "plt.xlabel('Sur les données réduites (PCA)')\n",
    "plt.ylabel('Sur les données complètes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e49f4c4-a784-4843-afad-d4c735880068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#on reclasse nos clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e036ac8-09a9-4b14-a3d3-f3de7d910360",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay(cm1).plot()\n",
    "plt.xlabel('On the reduced data (PCA)')\n",
    "plt.ylabel('On the complete data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3410fb2b-7792-4c18-9260-5c9b2174aae4",
   "metadata": {},
   "source": [
    "Ici aussi on remarque que les données sont très bien classées, la matrice est quasiment diagonale.\n",
    "\n",
    "Pour la suite des analyses, on va pouvoir les effectuer sur loading_pca, le jeu de données réduit car il représente très bien le jeu de données complet et permet de limiter les temps de calculs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcde27e-3dce-475c-bc47-3042b438fd9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#on convertit la table de confusion en dataframe \n",
    "df_cm =pd.DataFrame(cm1, columns=['groupe0', 'groupe1', 'groupe2','groupe3'], index=['groupe_pca0', 'groupe_pca1', 'groupe_pca2','groupe_pca3'])\n",
    "df_cm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6b75f3-884e-4bbb-bc9c-9ef503b0dbfc",
   "metadata": {},
   "source": [
    "En affichant la table de contingence, on voit que le nombre de stations mal classifié est très faible, cela nous permet de conclure (directement et non en passant par une CA) que nos méthodes de classification sont comparables. Et donc que nos méthodes de classification sur les données d'ACP réprésentent très bien la situation avec les données complètes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e13d040-a28e-42f6-9ada-0261b8e9090f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3.1.2. CAH : Agglomerative Clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538fa0ad-0b57-45cc-ae7d-fac24fe0bdce",
   "metadata": {},
   "source": [
    "Etudions ici la méthode de la classification ascendante hiérarchique (CAH). Cette méthode consiste à afficher des dendrogrammes des différente données en fonction de différents likages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4302fab-a338-495c-8b17-b371c583f2cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aef0ac-a814-421c-aeff-4e7cd750e9b2",
   "metadata": {},
   "source": [
    "La méthode CAH étant très coûteuse en termes de calculs, on préférera faire l'analyse en prenant un échantillon plus petit. Nous avons vu que l'analyse des données ACP donnait de bons résultats, donc pour faciliter les calculs, lors des analyses suivantes nous prendrons les données réduites. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbf8b82-e2b6-48d8-abc2-c0762e21b076",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Dimension du jeu de données entier 'loading' :\" , loading.shape)\n",
    "print(\"Dimension du jeu de données réduit 'loading_pca': \" +str(loading_pca.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63d6ec1-1e3e-4738-91ef-20ee734d0dc1",
   "metadata": {
    "tags": []
   },
   "source": [
    "On voit bien que la dimension est grandement réduite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbec0a3f-9755-4743-a828-287e7c965c8f",
   "metadata": {},
   "source": [
    "On détermine le nombre de clusters adéquats grâce aux critères graphiques, notamment le \"graphe du coude\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1ad5dc-b056-4cad-b98d-2f8d02c93d2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Réalisation du CAH avec le linkage 'Ward' \n",
    "ac = AgglomerativeClustering(linkage=\"ward\", compute_distances=True)\n",
    "clusterscah1= ac.fit_predict(loading_pca)\n",
    "\n",
    "#Affichage du nombre de clusters à garder en fonction du critère du coude\n",
    "ac = AgglomerativeClustering(linkage='ward', compute_distances=True)\n",
    "visualizer = KElbowVisualizer(ac, k=(1,12))\n",
    "\n",
    "visualizer.fit(loading_pca)  # Fit the data to the visualizer\n",
    "visualizer.show()   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c5d993-27ff-4805-b1e8-9527e498cb0f",
   "metadata": {},
   "source": [
    "D'après les résultats graphiques obtenus en R et en Python, nous décidons de prendre 4 clusters différents. Cela nous permet également d'être en accord avec le nombre de clusters de Kmeans.\n",
    "\n",
    "On affiche alors le dendrogramme associé en utilisant le linkage \"Ward\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf9c254-1b7e-47b7-b69e-d27c61eed1f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Nombre de clusters choisi par les indicateurs \n",
    "K = 4\n",
    "\n",
    "#Réalisation de la CAH avec le linkage 'Ward' pour K=4 clusters\n",
    "ac = AgglomerativeClustering(n_clusters=K, compute_distances=True, linkage='ward')\n",
    "clusterscah1 = ac.fit(loading_pca)\n",
    "print(clusterscah1)\n",
    "\n",
    "children = ac.children_\n",
    "distances = ac.distances_\n",
    "n_observations = np.arange(2, children.shape[0]+2)\n",
    "linkage_matrix = np.c_[children, distances, n_observations]\n",
    "\n",
    "sch.dendrogram(linkage_matrix, labels=ac.labels_)\n",
    "\n",
    "# On coupe le dendrogramme à K=4 clusters\n",
    "max_d = .5*(ac.distances_[-K]+ac.distances_[-K+1])\n",
    "plt.axhline(y=max_d, c='k')\n",
    "\n",
    "plt.title(\"Dendrogramme avec le linkage Ward\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f5bfca-099b-47e0-9fea-8b4aab9e94a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "On affiche tous les types de linkages que l'on a étudié pour voir les différences sur un même jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238aef99-2382-47b4-bd59-e694b1267019",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Affichage des dendrogrammes avec les différents linkages afin de pouvoir voir les différences sur un même jeu de données\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "linkage_matrix_single = sch.linkage(loading_pca, method='single')\n",
    "sch.dendrogram(linkage_matrix_single)\n",
    "plt.title(\"Dendrogramme avec le linkage simple\")\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "linkage_matrix_complete = sch.linkage(loading_pca, method='complete')\n",
    "sch.dendrogram(linkage_matrix_complete)\n",
    "plt.title(\"Dendrogramme avec le linkage complete\")\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "linkage_matrix_average = sch.linkage(loading_pca, method='average')\n",
    "sch.dendrogram(linkage_matrix_average)\n",
    "plt.title(\"Dendrogramme avec le linkage moyenne\")\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "linkage_matrix_ward = sch.linkage(loading_pca, method='ward')\n",
    "sch.dendrogram(linkage_matrix_ward)\n",
    "plt.title(\"Dendrogramme avec le linkage Ward\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ba09dc",
   "metadata": {},
   "source": [
    "Ainsi, les affichages nous montre bien que le likage \"Ward\" nous permet d'avoir des clusters de taille à peu près équivalentes (voir code R) et il nous permet de représenter des chargements moyens cohérents. De plus, on voit bien graphiquement que 4 clusters correspond bien au saut le plus important dans le graphe de 'Ward', la mesure de dissimilarité entre les clusters est élevé. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ed0d34-b5bc-41a3-812b-f95d2d3e8536",
   "metadata": {
    "tags": []
   },
   "source": [
    "De plus, la suite des interprétations sur R nous donne quasiment les mêmes informations que les KMeans, avec un cluster faiblement chargée en moyenne et qui varie peu qui contient la majorité des stations en altitude, et des clusters de jours et de nuits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b1e1a7-5833-4266-acbb-e9a8a8f3e7dc",
   "metadata": {},
   "source": [
    "#### 3.1.3. Gaussian Mixture Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67042bf-a8c0-41d3-a177-859f371e8f36",
   "metadata": {},
   "source": [
    "Afin de mettre en place la méthode du GMM, on applique un critère de sélection du nombre de clusters. On choisit ici de travailler avec le crière BIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0440e5b1-ffc3-411e-ad67-ff0c83ba335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Critère BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a90ea96-5114-4d6e-912b-bb2808b29bb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "k_max = 15\n",
    "\n",
    "bic = []\n",
    "for k in range(2, k_max):\n",
    "    gmm = GaussianMixture(n_components=k, init_params='kmeans', n_init=3)\n",
    "    gmm.fit(loading_pca)\n",
    "    bic.append(gmm.bic(loading_pca))\n",
    "bic = np.array(bic)\n",
    "\n",
    "plt.scatter(range(2, k_max), bic)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498f9364-c8b1-4a8c-a561-4ad80da95877",
   "metadata": {},
   "source": [
    "On cherche ici à obtenir le score BIC le plus petit possible, ainsi on voit que le modèle expliquant au mieux nos données contient 6 clusters.\n",
    "\n",
    "Nous décidons de faire notre étude avec 4 clusters en Python car ceci correspond aussi au nombre de clusters pris pour Kmeans, on à pas une grande différence de score BIC entre 4 et 6 clusters et enfin, avoir 6 clusters serait compliqué à interpréter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682e9d55-c17a-4fef-865d-3f1d3dabaafb",
   "metadata": {},
   "source": [
    "On affiche d'abord la dispersion des points par cluster initiée par le modèle de mélange gaussien (GMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcaea2a-7098-4b2b-bc29-7ff64aba3670",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "K = 4\n",
    "cmap = plt.get_cmap('Set3', K)\n",
    "\n",
    "gmm = GaussianMixture(n_components=K, n_init=3)\n",
    "clusters_gmm_loading = gmm.fit_predict(loading_pca)\n",
    "\n",
    "# --- #\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "scatter = plt.scatter(loading_pca[:,0], loading_pca[:,1], c=clusters_gmm_loading, s=1, linewidths=1, cmap='viridis')\n",
    "\n",
    "legend_labels = [f'Cluster {i+1}' for i in range(4)]\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=legend_labels)\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d566be9-ef60-4355-95b9-a2abf13748b3",
   "metadata": {},
   "source": [
    "Avant de continuer nos analyses\n",
    ", on va vérifier que la variance dans chaque cluster ne soit pas trop grande, ainsi les élèments d'un même cluster se comporteraient en moyenne de la même manière. <br> On affiche pour cela les boxplots des données de chaque cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d1a487-2229-469a-914d-9213768d82dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aux = pd.DataFrame({\n",
    "    'label': ['Cluster ' + str(label) for label in clusters_gmm_loading],\n",
    "    'proba': np.max(gmm.predict_proba(loading_pca), axis=1)\n",
    "})\n",
    "sns.boxplot(x='label', y='proba', data=aux, palette='Set3', showfliers=False )\n",
    "plt.title(\"Probabilité d'appartenance au cluster\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a60e35-8d36-42cf-b787-812554ebb63f",
   "metadata": {},
   "source": [
    "On peut voir que la plupart des stations semblent bien classées car leur probabilité d'appartenance au cluster est proche de 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a83ee2f-6a0f-40d2-8b9c-67e7550a3472",
   "metadata": {
    "tags": []
   },
   "source": [
    "On affiche désormais le plot mosaïque, qui permet de voir combien de stations de chaque cluster sont en altitude ou non:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aacb510-3c4c-4d4f-8742-daddcc83b62b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tbl1_1 = pd.crosstab(clusters_gmm_loading, coord['bonus'])\n",
    "\n",
    "#on affiche la mosaïque :\n",
    "tbl1_1.index = ['Cluster_1', 'Cluster_2', 'Cluster_3', 'Cluster_4'] \n",
    "tbl1_1.columns = ['Pas colline', 'Colline']  \n",
    "\n",
    "sns.heatmap(tbl1_1, cmap='coolwarm', annot=True, fmt=\"d\")\n",
    "plt.title(\"Stations en altitude en fonction du clusters\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464b491d-bea1-474e-95f6-fdf4a9593b78",
   "metadata": {},
   "source": [
    "On peut voir qu'un cluster comporte plus de stations en altitude que les autres en proportion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e057d9ef-fa28-4451-ad98-b7c684f59a40",
   "metadata": {},
   "source": [
    "On affiche maintenant le chargement moyen des stations par clusters (issus de GMM) au cours de la semaine. Cela va peut-être nous permettre de visualiser des tendances communes entre les éléments d'un même cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c332091-2d0e-4499-b86c-6ad54c6cebc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loading_sub5 = loading.iloc[:,:]\n",
    "loading_sub5['cluster']=clusters_gmm_loading\n",
    "mean_loading5=loading_sub5.groupby('cluster').mean()\n",
    "mean_loading5.head()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "col= ['purple', 'blue'  ,'green','yellow']\n",
    "\n",
    "# Affichage des 4 lignes sur le même graphique\n",
    "\n",
    "for i in range(4):\n",
    "    ax.plot(mean_loading5.columns, mean_loading5.iloc[i], label=f'Cluster {i+1}',color=col[i])\n",
    "\n",
    "    \n",
    "plt.legend()\n",
    "plt.title('Moyenne des chargements par cluster')\n",
    "plt.xlabel('Temps en heures')\n",
    "plt.ylabel('Moyenne des loading')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c589b6e0-011f-4c40-8afc-a2dbb682266c",
   "metadata": {},
   "source": [
    "On retrouve certains profils de clusters classiques : un cluster qui se charge en journée, qui pourrait correspondre aux zones de travails, et les autres clusters ont un profil de chargement plus nocturne. Le cluster avec un faible chargement en moyenne contient encore la majorité des stations en altitude. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ce40c9-71bc-41d2-ad77-8c3611dd378d",
   "metadata": {},
   "source": [
    "L'avantage d'avoir gardé 4 clusters en Python nous permet de faire une étude comparative des méthodes de classification comme ce qui suit : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c63e8d-30df-48dd-8bc0-7e5a86d94273",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay(confusion_matrix(clusters_gmm_loading, clusters_pca)).plot()\n",
    "plt.xlabel('On the reduced data (PCA)')\n",
    "plt.ylabel('On the complete data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d64d76d-fb5d-4e09-80fb-12197feb491d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm1_GMM, clusters_pca_sorted_jour_GMM = matchClasses(clusters_gmm_loading, clusters_pca)\n",
    "\n",
    "#Reclassement des groupes \n",
    "df_Kmeans_gmm1 = pd.DataFrame(cm1_GMM, columns=['groupe0', 'groupe1', 'groupe2','groupe3'], index=['groupe_pca0', 'groupe_pca1', 'groupe_pca2','groupe_pca3'])\n",
    "df_Kmeans_gmm1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbde6253-2df1-43e3-9e0a-01ecc5e543b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "En affichant la table de contingence, on voit que le nombre de stations mal classifié est important, on va réaliser une Analyse en Correspondance (CA) pour étudier la situation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0137ae-be50-47b0-9708-570d8d5875a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Réalisation de la CA \n",
    "ca = prince.CA(\n",
    "     n_components=14,\n",
    "     n_iter=10,\n",
    "     copy=True,\n",
    "     check_input=True,\n",
    "     engine='sklearn',\n",
    "     random_state=42)\n",
    "\n",
    "ca = ca.fit(df_Kmeans_gmm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1eac60-8481-463e-bc82-4d4ac4ed33ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affichage des valeurs propres \n",
    "display(ca.eigenvalues_summary)\n",
    "\n",
    "ca.scree_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7032f4-a3a8-44e5-a6db-898134771959",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_coord = ca.column_coordinates(df_Kmeans_gmm1)\n",
    "gpe_pca_coord = ca.row_coordinates(df_Kmeans_gmm1)\n",
    "\n",
    "display(gmm_coord)\n",
    "display(gpe_pca_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff88e2f-b61c-48cd-9e36-34463043a7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affichage des points \n",
    "plt.scatter(gmm_coord.iloc[:, 0], gmm_coord.iloc[:,1], color='blue', label='clusters_GMM') \n",
    "plt.scatter(gpe_pca_coord.iloc[:, 0], gpe_pca_coord.iloc[:, 1], color='green', label='Clusters_PCA') \n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa73bc3b-8832-4828-91da-83ff20e40da9",
   "metadata": {},
   "source": [
    "Ce graphe permet de projeter les points dans l'espace d'ACP, sur les composantes 0 et 1 qui expliquent à elles deux plus de 80% de la variance.\n",
    "\n",
    "On voit globalement que le cluster_gmm_i est représenté par le clusters_pca_i quelque soit i entre [0,3].\n",
    "\n",
    "En conclusion, on voit que les clusters issus des deux méthodes sont assez similaires pour l'ensemble des clusters et on peut donc conclure que les résultats de notre CA sont satisfaisants. Autrement dit nos deux méthodes de classifications classent de la même façon nos données. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c22c40-60df-4e8c-a5d9-5d42a86830ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.2. CA : comparaison entre Kmeans et Colline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923df914-d8d1-4977-bee0-a22beb02c2b7",
   "metadata": {},
   "source": [
    "On décide désormais d'étudier s'il existe un lien entre la classification opérée sur loading_pca par Kmeans et les stations localisées sur une colline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4268ef7-f121-472d-8499-e1c2a5e92a63",
   "metadata": {},
   "source": [
    "Pour ce faire, on réalise une Analyse en Correspondance. On commence par calculer la matrice de confusion :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c28897-8b08-4c63-b819-e12a6e6496b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(clusters_pca, coord['bonus'])\n",
    "print(cm[:,0:2])\n",
    "cm1 = cm[:,0:2]\n",
    "ConfusionMatrixDisplay(cm).plot()\n",
    "plt.xlabel('Groupes Hill 0 et 1')\n",
    "plt.ylabel('Clusters_pca issus de Kmeans')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2235bdf-cbc4-4d5d-ae0e-920701ef2dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#on convertit la table de confusion en dataframe \n",
    "df_cm = pd.DataFrame(cm1 , columns=['Pas colline', 'Colline'], index=['groupe_pca0', 'groupe_pca1', 'groupe_pca2','groupe_pca3'])\n",
    "df_cm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe580174",
   "metadata": {},
   "source": [
    "On utilise la bibliothèque CA du package \"prince\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee55d62b-8b3e-4c28-9cdf-9467da639a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Réalisation de la CA \n",
    "ca = prince.CA(\n",
    "     n_components=14,\n",
    "     n_iter=10,\n",
    "     copy=True,\n",
    "     check_input=True,\n",
    "     engine='sklearn',\n",
    "     random_state=42)\n",
    "\n",
    "ca = ca.fit(df_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f39dd8-00f7-44f6-9089-0def145ecc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affichage des valeurs propres \n",
    "display(ca.eigenvalues_summary)\n",
    "\n",
    "ca.scree_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0381b2-c062-4490-892b-35a3ea6506dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hill_coord = ca.column_coordinates(df_cm)\n",
    "gpe_coord = ca.row_coordinates(df_cm)\n",
    "\n",
    "display(hill_coord)\n",
    "display(gpe_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d322954-56f6-4255-ba27-19203b2e8dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affichage des points \n",
    "plt.scatter(hill_coord, [0, 0], color='blue', label='Hill')\n",
    "plt.scatter(gpe_coord, [0, 0, 0,0], color='green', label='Clusters')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117e2934",
   "metadata": {},
   "source": [
    "Ce graphe permet de projeter les points dans l'espace d'ACP. On voit que 3 clusters ainsi que les stations qui ne sont pas en altitude sont regroupées ensemble. Les stations en altitude sont éloignées de tous les clusters mais restent plus proche d'un cluster, elle vont donc majoritairement se situées dans celui-ci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16469fc9-3523-4739-adec-167fb2093154",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca.column_cosine_similarities(df_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3174fbf9",
   "metadata": {},
   "source": [
    "Cela nous permet de voir que les variables 'colline' - 'pas colline' très bien représentées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17925d5-0575-4c3a-821e-fc0f8ed5de12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca.row_cosine_similarities(df_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea10415",
   "metadata": {},
   "source": [
    "Cela nous permet de voir que les différents groupes de clusters formés sur les données pca sont très bien représentés."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab42cd3-857d-45f4-98e4-eeeb04d84dfb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Etude sur le jeu de données par jour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a59ebcc",
   "metadata": {},
   "source": [
    "Nous avons décidé de créer un nouveau jeu de données moyenné sur les jours afin d'espérer trouver de nouvelles déductions de nos données. Autrement dit, on crée un jeu de données qui comporte 7 vairables (pour les 7 jours de la semaine). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654ff471-5c28-4433-bcbe-ecac40bff885",
   "metadata": {},
   "source": [
    "### 4.1. ACP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c703ce2",
   "metadata": {},
   "source": [
    "On commence par regarder s'il est possible de réduire encore une fois la dimension de notre nouveau dataframe et de potentiellement en déduire des liens entre les taux de chargement et les jours. \n",
    "\n",
    "Pour ce faire, nous décidons de faire une ACP sur notre jeu de donneés."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b962ff",
   "metadata": {},
   "source": [
    "Ici encore la question de la standardisation des données se posent, or les données sont toujours comprises entre 0 et 1. Il n'est donc pas nécessaire de standardiser les données. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8ec037-f117-461b-955b-c634538e62f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lundi = loading.iloc[:, list(range(0, 24))].mean(axis=1)\n",
    "mardi = loading.iloc[:, list(range(24, 48))].mean(axis=1)\n",
    "mercredi = loading.iloc[:, list(range(48, 72))].mean(axis=1)\n",
    "jeudi = loading.iloc[:, list(range(72, 96))].mean(axis=1)\n",
    "vendredi = loading.iloc[:, list(range(96, 120))].mean(axis=1)\n",
    "samedi = loading.iloc[:, list(range(120, 144))].mean(axis=1)\n",
    "dimanche = loading.iloc[:, list(range(144, 168))].mean(axis=1)\n",
    "\n",
    "data_jours = pd.DataFrame({\n",
    "    'lundi': lundi,\n",
    "    'mardi': mardi,\n",
    "    'mercredi': mercredi,\n",
    "    'jeudi': jeudi,\n",
    "    'vendredi': vendredi,\n",
    "    'samedi': samedi,\n",
    "    'dimanche': dimanche\n",
    "})\n",
    "\n",
    "data_jours['Hill'] = coord['bonus']\n",
    "\n",
    "\n",
    "print(data_jours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35438bd-d678-437f-b34b-bae043070ee3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca_2 = PCA()\n",
    "data_jours_pca = pca_2.fit_transform(data_jours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c8fcae-ca8f-4028-bb06-4991efff82c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#On affiche la variance expliquée par les composantes de l'ACP\n",
    "plt.plot(np.cumsum(pca_2.explained_variance_ratio_))\n",
    "\n",
    "plt.title('Variance cumulée expliquée en fonction de la dimension de l espace de l`ACP')\n",
    "plt.xlabel('Nombre de composantes dans l ACP')\n",
    "plt.ylabel('Variance cumulée expliquée')\n",
    "\n",
    "#On regarde le nombre de composantes exacts qu'il nous faut garder afin d'avoir un pourcentage expliqué égal à 85%\n",
    "pca_2 = PCA(0.85).fit(data_jours) \n",
    "\n",
    "#Nombre de composantes gardées pour l'ACP\n",
    "pca_2.n_components_ \n",
    "print(f\"on garde {pca_2.n_components_} composantes pour le PCA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59adbab",
   "metadata": {},
   "source": [
    "La fonction nous dit qu'il faut garder 3 composantes pour expliquer 85% de la variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35882d43-1f72-48ca-bde9-6e16324c0cc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Réalisation de l'ACP avec 2 composantes\n",
    "pca_2=PCA(n_components=2)\n",
    "data_jours_pca = pca_2.fit_transform(data_jours) \n",
    "print(100*pca_2.explained_variance_ratio_)\n",
    "\n",
    "#Affichage et vérification de la dimension du jeu de données avant et après ACP\n",
    "print('--- PCA ---')\n",
    "print('Dimension initiale :' , data_jours.shape)\n",
    "print('Dimension après projection:', data_jours_pca.shape)\n",
    "\n",
    "print('')\n",
    "\n",
    "print('--- Variance expliquée  ---')\n",
    "print('Composante 1:', round(pca.explained_variance_[0],2), 'i.e.', round(100*pca.explained_variance_ratio_[0],2), '% de la variance totale')\n",
    "print('Composante 2:', round(pca.explained_variance_[1],2), 'i.e.', round(100*pca.explained_variance_ratio_[1],2), '% de la variance totale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9984b506-2c12-412a-9cad-d7224539850f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Affichage des bar plot de la proportion d'explication de la variance par chaque composante de l'ACP\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=[f\"PC{i+1}\" for i in range(len(pca_2.explained_variance_ratio_))], y=pca_2.explained_variance_ratio_ * 100)\n",
    "plt.xlabel(\"Composantes Principales\")\n",
    "plt.ylabel(\"Pourcentage de Variance Expliquée\")\n",
    "plt.title(\"Proportion de Variance Expliquée par Chaque Composante Principale\")\n",
    "plt.ylim(0, 80) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df64d5ca-8f09-4cf7-b9fe-79bde1def6bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Affichage des boxplots des composantes de l'ACP\n",
    "box = plt.boxplot(data_jours_pca[:,:10], patch_artist=True)\n",
    "plt.setp(box[\"boxes\"], facecolor=\"coral\", alpha=.5)\n",
    "plt.title(\"Box plots des 2 premières composantes\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b810bc90",
   "metadata": {},
   "source": [
    "On projette nos données dans sur les axes de l'ACP :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc24d2d1-a7ca-4542-a743-b874144bd702",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coord1 = pca.components_[0] * np.sqrt(pca_2.explained_variance_[0])\n",
    "coord2 = pca.components_[1] * np.sqrt(pca_2.explained_variance_[1])\n",
    "\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "\n",
    "arrow_length_factor = 5\n",
    "\n",
    "for i, j, nom in zip(coord1, coord2, data_jours.columns):\n",
    "    plt.text(i*arrow_length_factor, j*arrow_length_factor, nom, fontsize=10)\n",
    "    plt.arrow(0, 0, i* arrow_length_factor, j* arrow_length_factor, color = 'purple', alpha=0.7, width = 0.001)\n",
    "\n",
    "plt.axis((-0.4, 0.4, -0.4, 0.4))\n",
    "plt.gcf().gca().add_artist(plt.Circle((0, 0), radius = 0.4, color = 'cornflowerblue', fill = False))\n",
    "\n",
    "plt.title('Carte de projection - PCA')\n",
    "plt.xlabel('Composante principale 1')\n",
    "plt.ylabel('Composante principale 2')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153b5170-131d-4937-aee9-06336cbb5b10",
   "metadata": {},
   "source": [
    "L'ACP nous dit donc que l'on peut expliquer les jours de la semaine avec deux variables au lieu de 7, pour expliquer + de 90% de la variance. Cependant comme pour l'ACP précédente les affichages sont pas jolis. \n",
    "En R les variables sont plus interprétables et s'adaptent aux dimensions projetées. En Python, les résultats sont inaterprétables. \n",
    "\n",
    "Les projections dans les plans d'ACP (en R) nous permettent de faire l'hypothèses suivantes : \n",
    "- la composante 1 semble correspondre au chargement des stations comme dans le jeu de données complet. \n",
    "- la composante 2 semble faire la distinction semaine/week-end\n",
    "\n",
    "Cependant, les variables ne sont pas très bien projeté sur la dimension 2 donc cela reste à nuancer. Les variables étaient mieux projetées sur la dimension 2 en utilisant le jeu de données complet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a1eba6-3093-4f07-9be6-6b38ee33584e",
   "metadata": {},
   "source": [
    "#### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6577bb59-1b9a-433f-abb9-0e27719996a3",
   "metadata": {},
   "source": [
    "#### 4.1.1. Méthode de clustering avec k-means\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437300d0-ad10-41f9-91c8-54fdf7e4b77a",
   "metadata": {},
   "source": [
    "L'algorithme K-Means est une technique de classification non-supervisée des données. Il cherche à minimiser les distances entre les observations et les centres des clusters auxquels elles appartiennent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35c9cf6-cbf7-4b64-ba90-a75ec086ccf0",
   "metadata": {},
   "source": [
    "Tout d'abord, on va effectuer l'algorithme K-Means sur le jeu de données complet 'data_jours' et voir si on peut en tirer quelques interprétations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3966eb-9545-4662-ba24-0aa83075f8ac",
   "metadata": {},
   "source": [
    "On va déterminer le nombre de clusters optimal grace à la méthode du coude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90adf1c6-2c84-426e-8f87-2212bc2ba2df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inertia = []\n",
    "for k in range(1, 15):\n",
    "    kmeans_jours = KMeans(n_clusters=k, init='random', n_init='auto', max_iter=100, random_state=42)\n",
    "    kmeans_jours.fit(data_jours)\n",
    "    inertia.append(kmeans_jours.inertia_)\n",
    "inertia = np.array(inertia)\n",
    "\n",
    "\n",
    "plt.scatter(range(2, 15), inertia[1:])\n",
    "plt.xlabel('nombre de clusters', fontsize = 15)\n",
    "plt.ylabel('inertie', fontsize = 15)\n",
    "plt.title(\"Graphe du coude\", fontsize = 15)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- #\n",
    "\n",
    "\n",
    "#avec yellowbrick\n",
    "\n",
    "kmeans_jours = KMeans(init='random', n_init='auto', max_iter=100, random_state=42)\n",
    "visualizer = KElbowVisualizer(kmeans_jours, k=(1,12))\n",
    "\n",
    "visualizer.fit(data_jours)    \n",
    "visualizer.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699dbf2e-bcf2-4f9d-8b80-2678913e3abd",
   "metadata": {},
   "source": [
    "D'après les graphes précedents, on peut prendre 3 ou 4. Pour la suite, on va probablement choisir 3 clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b58b7c2-bc1a-4a75-9c67-f3e5c7919772",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(15,8))\n",
    "\n",
    "for k in range(2, 6):\n",
    "    kmeans_jours = KMeans(n_clusters=k, init='random', n_init='auto', max_iter=100, random_state=42)\n",
    "    q, mod = divmod(k, 2) \n",
    "    visualizer = SilhouetteVisualizer(kmeans_jours, colors='yellowbrick', ax=ax[q-1][mod])\n",
    "    visualizer.fit(data_jours)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab404692-d81c-4a06-b1e0-4a9d9d0db111",
   "metadata": {},
   "source": [
    "Ce résultat est vérifié par les graphes du score silhouette ci-dessous car pour 3 clusters il y a peu de valeurs négatives et que les bandes dépassent le trait rouge. On choisira pour la suite de l'analyse 3 clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef0b950-6a91-4c9e-917b-df595139f725",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "K = 3\n",
    "kmeans_jours = KMeans(n_clusters=K, init='random', n_init='auto', random_state=0)\n",
    "clusters_jours = kmeans_jours.fit_predict(data_jours)\n",
    "#On fixe le nombre de clusters à 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1ad4ad-d0b6-4413-b3a7-46d4474931e0",
   "metadata": {},
   "source": [
    "Observons mainteant la répartition des valeurs dans chaque clusters. Pour voir si certains clusters sont plus importants que d'autres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770c8acf-a2ff-46ca-a45a-7c2e2f81f1d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('Set3',K)\n",
    "plt.bar(*np.unique(clusters_jours, return_counts=True), color=cmap.colors)\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5259aecb-5a5f-4385-854f-6094b15deea5",
   "metadata": {},
   "source": [
    "La répartition des valeurs est très hétérogène, il n'y a que très peu de valeurs dans le 3ème cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5ad602-aef6-41b2-baa8-53b7e7aa266b",
   "metadata": {},
   "source": [
    "Avant de tirer des conclusions des analyses qui vont suivre, il faut vérifier que la variance intra-classe de chaque clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78314df4-e5e7-44de-9260-da2f54739e1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# distance de chaque point de données à son centre de cluster\n",
    "distances = kmeans_jours.transform(data_jours)\n",
    "\n",
    "#variance intraclasse pour chaque cluster\n",
    "variances = []\n",
    "for cluster in range(kmeans_jours.n_clusters):\n",
    "    cluster_distances = distances[kmeans_jours.labels_ == cluster, cluster]\n",
    "    variance = np.var(cluster_distances)\n",
    "    variances.append(variance)\n",
    "\n",
    "# Affichage\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(range(kmeans_jours.n_clusters), variances, color='skyblue')\n",
    "plt.xlabel('Clusters')\n",
    "plt.ylabel('Variance intra-classe')\n",
    "plt.title('Variance intra-classe par cluster')\n",
    "plt.xticks(range(kmeans_jours.n_clusters), [f'Cluster {i+1}' for i in range(kmeans_jours.n_clusters)])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5342ed22-55df-44e6-9bb1-17df6ebcf9e5",
   "metadata": {},
   "source": [
    "On voit que la variance des clusters est très petite, nous pouvons continuer nos analyses. <br>\n",
    "On affiche maintenant les boxplots qui illustre la répartition des distances de chaque point au centre de son cluster. Nous allons vérifier que cette distribution est dans une fenêtre assez réduite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63739134-d324-4701-9cf5-fabff932bd83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculer les distances de chaque point de données à son centre de cluster\n",
    "distances = kmeans_jours.transform(pd.DataFrame(data_jours))\n",
    "\n",
    "# Créer une liste de distances pour chaque cluster\n",
    "distances_per_cluster = [[] for _ in range(kmeans_jours.n_clusters)]\n",
    "for cluster in range(kmeans_jours.n_clusters):\n",
    "    cluster_distances = distances[kmeans_jours.labels_ == cluster, cluster]\n",
    "    distances_per_cluster[cluster] = cluster_distances\n",
    "\n",
    "# Plotter les boxplots\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(distances_per_cluster, patch_artist=True, labels=[f'Cluster {i+1}' for i in range(kmeans_jours.n_clusters)])\n",
    "plt.xlabel('Clusters')\n",
    "plt.ylabel('Distance au centre de cluster')\n",
    "plt.title('Distribution des distances au centre de cluster')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc418ca-7d9d-40d8-8b8f-826d9983ac33",
   "metadata": {},
   "source": [
    "Les boxplots associés à chaque clusters ne sont pas très longs, cela est une autre façon d'illustrer les résultats précédents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8e925a-2481-4271-b59a-2fc69eb0c647",
   "metadata": {},
   "source": [
    "On va afficher maintenant le chargement moyen des stations par clusters au cours de la semaine. Cela va peut-être nous permettre de visualiser des tendances communes entre les éléments d'un même cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644d09d9-b80a-45e0-8843-c4240f9c6d91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loading_sub3 = loading.iloc[:,:]\n",
    "loading_sub3['cluster']=clusters_jours\n",
    "mean_loading3=loading_sub3.groupby('cluster').mean()\n",
    "mean_loading3.head()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "col = ['#800080','#008080','#FFFF00']\n",
    "\n",
    "# Affichage des 4 lignes sur le même graphique\n",
    "for i in range(3):\n",
    "    ax.plot(mean_loading3.columns, mean_loading3.iloc[i], label=f'Cluster {i+1}',color=col[i])\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Moyenne des chargements par cluster')\n",
    "plt.xlabel('Temps en heures')\n",
    "plt.ylabel('Moyenne des loading')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b9eb5a-d2e9-4834-a021-8329856b0b7a",
   "metadata": {},
   "source": [
    "Sur le dataframe des données regoupées par jours, les interprétations des clusters sont différentes. On peut voir que les clusters se différencient surtout sur leur moyenne de chargement. \\\n",
    "Le cluster 2 correspond aux stations peu chargées en moyenne. \\\n",
    "Le cluster 3 correspond aux stations moyennement chargées.\\\n",
    "Enfin, le cluster 1 correspond lui, aux stations chargées.\\\n",
    "On voit peu de différence entre la semaine/weekend sur le profil de chargement comparé à data_heures (et data_heures_pca) où la moyenne de chargement des clusters étaient complétement différentes en fonction de l'heure. \n",
    "Cela confirme notre analyse descriptive : le week-end a peu d'influence sur le chargement des stations. Cela a également pu se voir par le peu d'information que porte la composante 2 dans l'acp sur data_jours (8,2%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918a9199-5fc8-4850-891d-05f9aa0aa554",
   "metadata": {},
   "source": [
    "On va maintenant tenter de faire un lien entre la variable 'Hill' est les clusters formés par K-Means. Pour ce faire, on dresse une table croisée qui va mettre en lien 'Hill' et les clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e7b464-9071-447e-a1de-23aa7b203f58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tbl3 = pd.crosstab(clusters_jours, coord['bonus'])\n",
    "\n",
    "#on affiche la mosaïque :\n",
    "tbl3.index = ['Cluster_1', 'Cluster_2', 'Cluster_3'] \n",
    "tbl3.columns = ['Pas colline', 'Colline']  \n",
    "\n",
    "sns.heatmap(tbl3, cmap='coolwarm', annot=True, fmt=\"d\")\n",
    "plt.title(\"Stations en altitude en fonction du clusters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e55cf8-17a0-48cd-b721-388af28d4031",
   "metadata": {},
   "source": [
    "Les stations en altitude sont, dans ce cas aussi, regroupées globalement dans un seul cluster (ici le 2ème). En effet, 125 stations en altitudes sont contenues dans le 2ème cluster. Ce cluster correspond aux stations les plus souvent vides. Cela peut s'interpreter par le fait que beaucoup de personnes sur les collines empruntent un vélo pour descendre mais elles ont tendance à ne pas monter la colline en vélo. Les stations en altitude sont donc vides car les gens ne ramènent pas les vélos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9a41af-15d6-4347-b395-fe617021ca03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Etude sur data_jours_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d8172c-2525-4926-bb3b-6d63c1d4d60e",
   "metadata": {},
   "source": [
    "Maintenant, on va effectuer l'algorithme K-Means à nouveau mais cette fois-ci, sur le jeu de données réduit par l'ACP. Cela va permettre de voir si les données réduites représentent bien le jeu de données complet. On cherche entre autre à voir si la classification réalisée sur le jeu de données complet et la même sur celui réduit, si c'est le cas cela nous permettra de simplifier les calculs des algorithmes suivants en travaillant sur le jeu de données réduit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68f95b7-b7ce-4105-b304-4cf298ed043b",
   "metadata": {},
   "source": [
    "Déterminons le nombre de cluster optimal :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93a90bc-7b48-4296-97fb-ab2bdd9e6311",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inertia = []\n",
    "for k in range(1, 15):\n",
    "    kmeans_PCA_jours = KMeans(n_clusters=k, init='random', n_init='auto', max_iter=100, random_state=42)\n",
    "    kmeans_PCA_jours.fit(data_jours_pca )\n",
    "    inertia.append(kmeans_PCA_jours.inertia_)\n",
    "inertia = np.array(inertia)\n",
    "\n",
    "\n",
    "plt.scatter(range(2, 15), inertia[1:])\n",
    "plt.xlabel('nombre de clusters', fontsize = 15)\n",
    "plt.ylabel('inertie', fontsize = 15)\n",
    "plt.title(\"Graphe du coude\", fontsize = 15)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- #\n",
    "\n",
    "\n",
    "# avec yellowbrick\n",
    "\n",
    "kmeans_PCA_jours = KMeans(init='random', n_init='auto', max_iter=100, random_state=42)\n",
    "visualizer = KElbowVisualizer(kmeans_PCA_jours, k=(2,12))\n",
    "\n",
    "visualizer.fit(data_jours_pca )   \n",
    "visualizer.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452bff57-4249-4e4b-b01c-7ad05d54b182",
   "metadata": {},
   "source": [
    "D'après les graphes précedents on pourrait choisir un nombre de clusters de 4.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f625b6-ad77-405f-89a4-edc826c86383",
   "metadata": {},
   "source": [
    "Nous allons vérifier ce résultat par l'analyse des scores silhouette."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147ca484-f5a7-4970-9424-dcdc8174ac12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(15,8))\n",
    "\n",
    "for k in range(2, 6):\n",
    "    kmeans_PCA_jours = KMeans(n_clusters=k, init='random', n_init='auto', max_iter=100, random_state=42)\n",
    "    q, mod = divmod(k, 2) \n",
    "    # Create SilhouetteVisualizer instance with KMeans instance\n",
    "    visualizer = SilhouetteVisualizer(kmeans_PCA_jours, colors='yellowbrick', ax=ax[q-1][mod])\n",
    "    visualizer.fit(data_jours_pca )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97315871-3ca8-4af0-9727-c14ff0270a05",
   "metadata": {},
   "source": [
    "Ces score silhouettes montrent que 3 ou 4 clusters est un bon choix, il y a pour les deux très peu de valeurs négatives et les bandes dépassent le trait rouge. Pour tenter de coller à l'analyse des données non réduites, on va choisir 3 clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd11477-f818-40dd-af31-4a77a222ccf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "K = 3\n",
    "kmeans_PCA_jours = KMeans(n_clusters=K, init='random', n_init='auto', random_state=0)\n",
    "clusters_jours_pca = kmeans_PCA_jours.fit_predict(data_jours_pca )\n",
    "#On fixe le nombre de cluster à 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb8317a-fc2d-45de-8d95-e6c06685d4bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#reclassement des clusters pour matcher les couleurs et faire correspondre les clusters \n",
    "cm2, clusters_jours_pca_sorted = matchClasses(clusters_jours, clusters_jours_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b1c3d0-885b-4d53-8941-ca093eb6dd77",
   "metadata": {},
   "source": [
    "Observons maintenant la répartition des valeurs dans chaque cluster. Pour voir si certains clusters sont plus importants que d'autres et si cela correspond à l'analyse des données complètes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0367c745-b868-431d-8fd3-599e45ae117b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('Set3',K)\n",
    "plt.bar(*np.unique(clusters_jours_pca_sorted, return_counts=True), color=cmap.colors)\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457ff489-7471-4955-8224-e170f01eceb4",
   "metadata": {},
   "source": [
    "La répartition des valeurs est la même que précédemment, le cluster 3 ne possède pas beaucoup de valeurs comparé aux deux autres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22b5b27-f231-4b8f-b86e-4cb3a8b34a67",
   "metadata": {},
   "source": [
    "Avant de tirer des conclusions des analyses qui vont suivre, il faut vérifier que la variance intra-classe de chaque clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c11c33-28bd-427c-bc91-da156a605783",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# distance de chaque point de données à son centre de cluster\n",
    "distances = kmeans_PCA_jours.transform(data_jours_pca)\n",
    "\n",
    "#variance intraclasse pour chaque cluster\n",
    "variances = []\n",
    "for cluster in range(kmeans_PCA_jours.n_clusters):\n",
    "    cluster_distances = distances[kmeans_PCA_jours.labels_ == cluster, cluster]\n",
    "    variance = np.var(cluster_distances)\n",
    "    variances.append(variance)\n",
    "\n",
    "# Affichage\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(range(kmeans_PCA_jours.n_clusters), variances, color='skyblue')\n",
    "plt.xlabel('Clusters')\n",
    "plt.ylabel('Variance intra-classe')\n",
    "plt.title('Variance intra-classe par cluster')\n",
    "plt.xticks(range(kmeans_PCA_jours.n_clusters), [f'Cluster {i+1}' for i in range(kmeans_PCA_jours.n_clusters)])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca99e08-8302-4fdb-a64a-5f1b770ccca2",
   "metadata": {},
   "source": [
    "La variance intra-classe est assez petite, nous choisissons de poursuivre les analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c95badf-0d89-43d4-8424-cac72b6415f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Définition des couleurs des clusters\n",
    "colors = ['#800080','#008080','#FFFF00']\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "# Tracé du nuage de points des clusters dans l'espace d'ACP\n",
    "scatter = plt.scatter(loading_pca[:, 0], loading_pca[:, 1], c=clusters_jours_pca, cmap='viridis', s=50, alpha=0.5)\n",
    "\n",
    "# Définition des étiquettes de légende pour chaque cluster\n",
    "legend_labels = ['Cluster 1', 'Cluster 2', 'Cluster 3']\n",
    "\n",
    "# Création des marqueurs de légende avec les couleurs correspondantes\n",
    "legend_markers = [plt.Line2D([0], [0], linestyle='none', marker='o', color=color, markersize=10) for color in colors]\n",
    "\n",
    "# Affichage de la légende avec les marqueurs et les étiquettes définis\n",
    "plt.legend(legend_markers, legend_labels, loc='lower right')\n",
    "\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('Clusters dans le plan de l\\'ACP')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58f4f8b-1c8c-4838-b244-6fa3513dbf8c",
   "metadata": {},
   "source": [
    "Les valeurs sont bien réparties entre les clusters et ne se mélangent pas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab81ef30-df43-464e-9f8b-e683a1a731b9",
   "metadata": {},
   "source": [
    "Nous allons maintenant voir si, dans ce cas aussi, la variable 'Hill' a un comportement particulier avec les clusters formés par K-Means. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29974d76-56ae-4149-897b-5e48b2df0901",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tbl3_1 = pd.crosstab(clusters_jours_pca_sorted, coord['bonus'])\n",
    "\n",
    "#on affiche la mosaïque :\n",
    "tbl3_1.index = ['Cluster_1', 'Cluster_2', 'Cluster_3'] \n",
    "tbl3_1.columns = ['Pas colline', 'Colline']  \n",
    "\n",
    "sns.heatmap(tbl3_1, cmap='coolwarm', annot=True, fmt=\"d\")\n",
    "plt.title(\"Stations en altitude en fonction du clusters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b792d9-a566-4de8-abcb-0041933aae5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Dans cette classification aussi, un cluster contient la majorité des stations en altitude. On peut faire les mêmes déductions que pour le Kmeans sur data_jours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192a51fa-cf7f-4c60-b5c1-b31dc45cdd57",
   "metadata": {},
   "source": [
    "On va afficher maintenant le chargement moyen des stations par cluster au cours de la semaine. Cela va peut-être nous permettre de visualiser des tendances communes entre les éléments d'un même cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a22750e-a9cb-4a41-8740-1944b73d36ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loading_sub4 = loading.iloc[:,:]\n",
    "loading_sub4['cluster']=clusters_jours_pca_sorted\n",
    "mean_loading4=loading_sub4.groupby('cluster').mean()\n",
    "mean_loading4.head()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "col = ['#800080','#008080','#FFFF00']\n",
    "\n",
    "# Affichage des 4 lignes sur le même graphique\n",
    "for i in range(3):\n",
    "    ax.plot(mean_loading4.columns, mean_loading4.iloc[i], label=f'Cluster {i+1}', color= col[i])\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Moyenne des chargements par cluster')\n",
    "plt.xlabel('Temps en heures')\n",
    "plt.ylabel('Moyenne des loading')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022519c8-7166-4fad-986c-f5fcef85727a",
   "metadata": {},
   "source": [
    "Comme précédemment, on remarque un cluster qui représente les stations non chargées, un autre les stations moyennement chargées et enfin celles qui le sont le plus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d84a34-8bb3-493c-b077-263bf9730ad9",
   "metadata": {
    "tags": []
   },
   "source": [
    "Comparaison des deux classifications :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71af44f4-6a5d-4c1f-b474-e15d09e32af0",
   "metadata": {},
   "source": [
    "On compare les deux classifications grâce à un scatterplot pour voir le nombre de valeurs qui correspondent dans le cas normal et le cas réduit, afin de voir si il est vraiment utile de faire son analyse sur l'ACP ou non  :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121c4acf-39f7-4baf-8626-b29644db3eb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Position = np.array(coord)[:,0:2]\n",
    "\n",
    "#graphe à pour data_jours entier\n",
    "f1 = px.scatter_mapbox(clusters_jours, Position[:,1], Position[:,0], color=clusters_jours, color_continuous_scale=[(0, '#800080'), (0.5, '#008080'), (1, '#FFFF00')], \n",
    "                        size_max=15, zoom=10,mapbox_style=\"carto-positron\", opacity = .9,\n",
    "                        title = 'clusters données complètes')\n",
    "\n",
    "f1.show()\n",
    "\n",
    "#graphe à pour data_jours_pca\n",
    "f2 = px.scatter_mapbox(clusters_jours_pca_sorted, Position[:,1], Position[:,0], color=clusters_jours_pca_sorted, color_continuous_scale =[(0, '#800080'), (0.5, '#008080'), (1, '#FFFF00')], \n",
    "                        size_max=15, zoom=10,mapbox_style=\"carto-positron\", opacity = .9,\n",
    "                        title = 'clusters données pca')\n",
    "f2.show()\n",
    "\n",
    "\n",
    "\n",
    "points_diff = clusters_jours != clusters_jours_pca_sorted\n",
    "\n",
    "# Calcul du nombre de points différents\n",
    "num_diff_points = np.sum(points_diff)\n",
    "\n",
    "# Calcul du pourcentage de réussite\n",
    "pourcentage_reussite = (1- num_diff_points / len(clusters_jours)) * 100\n",
    "\n",
    "# Affichage du résultat\n",
    "print(f\"Nombre de points différents : {num_diff_points} sur {len(clusters_jours)}\")\n",
    "print(f\"Pourcentage de réussite : {pourcentage_reussite:.2f}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f10f62-c959-4e24-bb95-df0149f16ad6",
   "metadata": {},
   "source": [
    "Le pourcentage de réussite d'association des points est moins importante que pour l'étude précédente cependant il reste toujours assez important pour pouvoir considérer que les données réduites avec l'ACP réprésentent bien les données complètes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d72ca5b-294f-4705-973b-5d44234d1259",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay(confusion_matrix(clusters_jours, clusters_jours_pca)).plot()\n",
    "plt.xlabel('On the reduced data (PCA)')\n",
    "plt.ylabel('On the complete data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e78a7e-00db-4ff4-ad7c-82cde0a13a51",
   "metadata": {},
   "source": [
    "On visualise bien grâce à ce graphe que la majorité des valeurs sont bien réparties dans les 3 clusters différents mais sont mélangées, il faut les reclasser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423474d1-8bae-43f4-a80d-44c16cfecca5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reclassement des clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ae55aa-784b-4753-92f0-85a963fe970a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay(cm2).plot()\n",
    "plt.xlabel('On the reduced data (PCA)')\n",
    "plt.ylabel('On the complete data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90337f3-6c0c-46f1-b471-657982b763fa",
   "metadata": {},
   "source": [
    "Cette figure valide ce qui a été dit précedemment, soit que les données dans le plan réduit et dans le plan PCA correspondent bien. Pour la suite des analyses, on peut travailler uniquement sur les données réduit pour réduire le temps de calcul des algorithmes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5403a7eb-a362-47d2-9ad8-6a9840d78d06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#on convertit la table de confusion en dataframe \n",
    "df_cm2 = pd.DataFrame(cm2, columns=['groupe0', 'groupe1','groupe2'], index=['groupe_pca0', 'groupe_pca1','groupe_pca2',])\n",
    "df_cm2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd058704-008e-401c-aab2-5a5be7262ee5",
   "metadata": {},
   "source": [
    "En affichant la table de contingence, on voit que le nombre de stations mal classifié est très faible, cela nous permet de conclure (directement et non en passant par une CA) que nos méthodes de classification sont comparables. Ceci signifie que le  jeu de données complet et le jeu réduit ont des clusters qui correspondent bien, on va pouvoir considérer prendre les données réduites pour la suite de nos analyses pour faciliter les calculs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0932eaf1-4479-424a-83ac-1edf562f1d92",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 4.1.2. CAH : Agglomerative Clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6ebd4f-21c6-4bd1-9cd4-f7e28001c6a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "Etudions ici la méthode de la classification ascendante hiérarchique (CAH). Cette méthode consiste à afficher des dendrogrammes des différente données en fonction de différents likages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188d7469-3894-4ef1-9ba0-aa81da647de9",
   "metadata": {},
   "source": [
    "Comme expliqué précédemment, on préférera faire l'analyse en prenant un échantillon plus petit pour minimiser les temps de calculs. Nous avons vu que l'analyse des données PCA donnait de bons résultats, donc pour faciliter les calculs, lors des analyses suivantes nous prendrons les données jours réduites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e199438e-d98f-4f58-bf9c-8594568620bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Dimension du jeu de données entier 'loading' :\" , data_jours.shape)\n",
    "print(\"Dimension du jeu de données réduit 'loading_pca': \" +str(data_jours_pca.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99efcfc2-fc31-4767-97a5-89ae072cddde",
   "metadata": {},
   "source": [
    "Les données issues de la PCA sont donc bien réduites."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e787d7-4419-4742-840e-bf5ef61d497b",
   "metadata": {},
   "source": [
    "On détermine le nombre de clusters adéquats grâce au graphe du coude :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f299e323-c693-4f60-ba0d-3aaf8dfc8be0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Réalisation du CAH avec le linkage 'Ward' \n",
    "ac = AgglomerativeClustering(linkage=\"ward\", compute_distances=True)\n",
    "clusters_cah2 = ac.fit_predict(data_jours_pca)\n",
    "\n",
    "#Méthode d'affichage de sélection des clusters\n",
    "ac = AgglomerativeClustering(linkage='ward', compute_distances=True)\n",
    "visualizer = KElbowVisualizer(ac, k=(2,12))\n",
    "\n",
    "visualizer.fit(data_jours_pca) \n",
    "visualizer.show()   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46577706-a906-409a-b113-677d9ac0d24f",
   "metadata": {},
   "source": [
    "D'après les résultats graphiques obtenus en R et en Python, nous décidons de prendre 3 clusters différents.\n",
    "\n",
    "On affiche alors le dendrogramme associé en utilisant le linkage \"Ward\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4f28ff-239c-4e59-b7c5-50f90010f85d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Nombre de clusters choisi par les indicateurs \n",
    "K = 3\n",
    "\n",
    "#Réalisation du CAH avec le linkage 'Ward' & affichage du résultat en coupant à K = 3 clusters\n",
    "ac = AgglomerativeClustering(n_clusters=K, compute_distances=True, linkage='ward')\n",
    "clusterscah2 = ac.fit(data_jours_pca)\n",
    "\n",
    "children = ac.children_\n",
    "distances = ac.distances_\n",
    "n_observations = np.arange(2, children.shape[0]+2)\n",
    "linkage_matrix = np.c_[children, distances, n_observations]\n",
    "\n",
    "sch.dendrogram(linkage_matrix, labels=ac.labels_)\n",
    "\n",
    "# On coupe le dendrogramme à K =3 clusters \n",
    "max_d = .5*(ac.distances_[-K]+ac.distances_[-K+1])\n",
    "plt.axhline(y=max_d, c='k')\n",
    "\n",
    "plt.title(\"Dendrogramme avec le linkage Ward\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04906519-7ea4-4d0f-bd3b-6522a02b45da",
   "metadata": {},
   "source": [
    "On affiche tous les types de linkages que l'on a étudié pour montrer que \"Ward\" et \"complete\" sont les deux types dont les graphes sont faciles à explorer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a417cdf6-63fe-46b2-93a7-f6f0c33e9597",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affichage des dendrogrammes avec les différents linkages afin de pouvoir voir les différences sur un même jeu de données\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "linkage_matrix_single = sch.linkage(data_jours_pca, method='single')\n",
    "sch.dendrogram(linkage_matrix_single)\n",
    "plt.title(\"Dendrogramme avec le linkage simple\")\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "linkage_matrix_complete = sch.linkage(data_jours_pca, method='complete')\n",
    "sch.dendrogram(linkage_matrix_complete)\n",
    "plt.title(\"Dendrogramme avec le linkage complete\")\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "linkage_matrix_average = sch.linkage(data_jours_pca, method='average')\n",
    "sch.dendrogram(linkage_matrix_average)\n",
    "plt.title(\"Dendrogramme avec le linkage moyenne\")\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "linkage_matrix_ward = sch.linkage(data_jours_pca, method='ward')\n",
    "sch.dendrogram(linkage_matrix_ward)\n",
    "plt.title(\"Dendrogramme avec le linkage Ward\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f816517e",
   "metadata": {},
   "source": [
    "On voit que le graphe issu du linkage 'simple' est illisible, les autres sont mieux mais c'est sur le graphe du linkage 'Ward' qu'on voit le mieux le 'jump' important formant les 3 clusters de tailles assez similaires. Donc on garde le linkage 'Ward'. \n",
    "\n",
    "Les interprétations sur R nous donne les mêmes informations que les KMeans."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c53d18-8b97-44c1-88e4-39378452e83c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 4.1.3. Gaussian Mixture Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2346b2ac-612c-4309-b9c1-39d709945289",
   "metadata": {},
   "source": [
    "On peut utiliser les données issues de l'ACP car elle résume bien notre jeu de données 'jours'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad19a62-8a4a-45e8-941e-0406dcbc8d8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "Afin de mettre en place la méthode du GMM, on applique un critère de sélection du nombre de clusters. On choisit ici de travailler avec le crière BIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f0f9c0-0ee3-48a4-b619-ebf666c86ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Critère BIC :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3494f5-4882-4a38-b9fa-7a1fe3ee99d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "k_max = 15\n",
    "\n",
    "bic = []\n",
    "for k in range(2, k_max):\n",
    "    gmm = GaussianMixture(n_components=k, init_params='kmeans', n_init=3)\n",
    "    gmm.fit(data_jours_pca)\n",
    "    bic.append(gmm.bic(data_jours_pca))\n",
    "bic = np.array(bic)\n",
    "\n",
    "plt.scatter(range(2, k_max), bic)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc75449-db14-42b5-9e3e-a8364d78bfbc",
   "metadata": {},
   "source": [
    "En appliquant le critère BIC on devrait garder 5 variables pour expliquer nos données en Python et on trouve 4 en R. Ce qui se rapproche globalement de ce que l'on a trouvé par la méthode du coude précédemment. On décide de garder 3 variables pour être en accord avec le nombre de clusters dans Kmeans et faire une interprétation globale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b3f4dc-28eb-475c-b3b0-2b38ca9d9126",
   "metadata": {},
   "source": [
    "On affiche d'abord la dispersion des points par cluster initiée par le modèle de mélange gaussien (GMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41600c76-77fc-4831-b02e-40826da7b72b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "K = 3\n",
    "cmap = plt.get_cmap('Set3', K)\n",
    "\n",
    "gmm = GaussianMixture(n_components=K, n_init=3)\n",
    "clusters_gmm_jours = gmm.fit_predict(data_jours_pca)\n",
    "\n",
    "# --- #\n",
    "\n",
    "\n",
    "# Définition des couleurs des clusters\n",
    "colors = ['#800080','#008080','#FFFF00']\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "# Tracé du nuage de points des clusters dans l'espace d'ACP\n",
    "scatter = plt.scatter(loading_pca[:, 0], loading_pca[:, 1], c=clusters_gmm_jours, cmap='viridis', s=50, alpha=0.5)\n",
    "\n",
    "# Définition des étiquettes de légende pour chaque cluster\n",
    "legend_labels = ['Cluster 1', 'Cluster 2', 'Cluster 3']\n",
    "\n",
    "# Création des marqueurs de légende avec les couleurs correspondantes\n",
    "legend_markers = [plt.Line2D([0], [0], linestyle='none', marker='o', color=color, markersize=10) for color in colors]\n",
    "\n",
    "# Affichage de la légende avec les marqueurs et les étiquettes définis\n",
    "plt.legend(legend_markers, legend_labels, loc='lower right')\n",
    "\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('Clusters dans le plan de l\\'ACP')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4bfc1e-6209-4e9f-bbf5-c2eec035871c",
   "metadata": {},
   "source": [
    "On obtient des clusters très surprenants par rapport à ceux obtenus sur les autres méthodes de classifications ou les autres jeux de données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a658d99-2e9b-402f-bc99-ceae67bdf5e3",
   "metadata": {},
   "source": [
    "Avant de continuer nos analyses\n",
    ", on va vérifier que la variance dans chaque cluster ne soit pas trop grande, ainsi les élèments d'un même cluster se comporteraient en moyenne de la même manière. <br> On affiche pour cela les boxplots des données de chaque cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6eedea-12d2-493b-8a21-b1c2293bca51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aux = pd.DataFrame({\n",
    "    'label': ['Cluster ' + str(label) for label in clusters_gmm_jours],\n",
    "    'proba': np.max(gmm.predict_proba(data_jours_pca), axis=1)\n",
    "})\n",
    "sns.boxplot(x='label', y='proba', data=aux, palette='Set3', showfliers=False)\n",
    "plt.title('Cluster Probabilities')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21de18fe-e550-4a43-b29a-e5b24d405acf",
   "metadata": {},
   "source": [
    "Les variances des données dans chaque cluster, représentée par la longueur des boxplots, est relativement faible, on peut continuer nos analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62e4fa5-e491-4da5-bc25-3bf91bd73ac9",
   "metadata": {},
   "source": [
    "On affiche maintenant le chargement moyen des stations par cluster (issus de GMM) au cours de la semaine. Cela va peut-être nous permettre de visualiser des tendances communes entre les éléments d'un même cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42119be0-c4f3-4b24-943b-0d0465e1ddd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loading_sub5_2 = loading.iloc[:,:]\n",
    "loading_sub5_2['cluster']=clusters_gmm_jours\n",
    "mean_loading5=loading_sub5_2.groupby('cluster').mean()\n",
    "mean_loading5.head()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "col= ['purple', 'blue'  ,'green']\n",
    "\n",
    "# Affichage des 4 lignes sur le même graphique\n",
    "\n",
    "for i in range(3):\n",
    "    ax.plot(mean_loading5.columns, mean_loading5.iloc[i], label=f'Cluster {i+1}',color=col[i])\n",
    "\n",
    "    \n",
    "plt.legend()\n",
    "plt.title('Moyenne des chargements par cluster')\n",
    "plt.xlabel('Temps en heures')\n",
    "plt.ylabel('Moyenne des loading')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f2855f-7b31-4d80-920d-314ec89bb142",
   "metadata": {},
   "source": [
    "On affiche désormais le plot mosaïque, qui permet de voir combien de stations de chaque cluster sont en altitude ou non:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1674b7c9-cc32-4eb2-b7d7-3b5511c9f16c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tbl2_3 = pd.crosstab(clusters_gmm_jours, coord['bonus'])\n",
    "\n",
    "#on affiche la mosaïque :\n",
    "tbl2_3.index = ['Cluster_1', 'Cluster_2', 'Cluster_3'] \n",
    "tbl2_3.columns = ['Pas colline', 'Colline']  \n",
    "\n",
    "sns.heatmap(tbl2_3, cmap='coolwarm', annot=True, fmt=\"d\")\n",
    "plt.title(\"Stations en altitude en fonction du clusters\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4c3548-fc6c-4c63-b946-bde6328acdce",
   "metadata": {},
   "source": [
    "Notre plot mosaïque nous permet de dire qu'un clutser contient les stations localisées sur des collines, ce qui rejoint le graphe des moyennes de chargment où le chargement est assez bas. Cela rejoint ce que l'on a dit sur l'analyse de Kmeans. Concernant le chargement moyen des différents clusters et sur le fait que les stations en altitude sont toutes dans le cluster 3 qui correspond aux stations faiblement chargées en moyenne.\n",
    "Cependant, dans cette méthode le cluster_3 comporte plus de variations : il a tendance à se charger la nuit et se vider d'un coup le matin les jours de semaine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33431a1-2c8d-44b8-95e4-00b3e0beec84",
   "metadata": {},
   "source": [
    "Réalisons maintenant une étude comparative des différentes méthodes de clusters : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f30e822-286b-4031-8a52-7743b3757268",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm2_GMM, clusters_pca_sorted_heures_GMM = matchClasses(clusters_gmm_jours, clusters_jours_pca)\n",
    "\n",
    "\n",
    "ConfusionMatrixDisplay(cm2_GMM).plot()\n",
    "\n",
    "plt.xlabel('Kmeans sur les données jours réduites (PCA)')\n",
    "plt.ylabel('Gmm sur les données jours réduites ')\n",
    "plt.show()\n",
    "\n",
    "df_kmeans_gmm2 = pd.DataFrame(cm2_GMM, columns=['groupe0', 'groupe1','groupe2'], index=['groupe_pca0', 'groupe_pca1','groupe_pca2'])\n",
    "df_kmeans_gmm2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b85eb97-fa58-4a55-b336-8d5b7c6cd338",
   "metadata": {},
   "source": [
    "En affichant la table de contingence, on voit que le nombre de stations mal classifié est très faible, cela nous permet de conclure (directement et non en passant par une CA) que nos méthodes de classification sont comparables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d21c86-444a-430e-b920-0a37e54979b8",
   "metadata": {},
   "source": [
    "En R, on réalise égalemetn une Analyse en Correspondance entre les méthodes CAH et Kmeans pour ce jeu de données data_jours, afin de comparer les méthodes de classifications. On peut voir que les clusters entre K-Means et CAH sur data_jours sont quasiment les mêmes alors que entre GMM et K-Means les clusters ne sont pas exactement pareil, d'où la différence par exemple entre la distribution des stations en altitude dans les clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7c5e20-8820-4203-b788-4b187c2ecb9a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. Etude sur le jeu de données par heures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b16b1ef",
   "metadata": {},
   "source": [
    "Nous réalisons encore une fois un nouveau dataframe en regroupant les taux moyens par heures de la journée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd231c5-1d6c-474d-b77e-4cd84bad9b89",
   "metadata": {},
   "source": [
    "### 5.1. ACP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2fe2c4",
   "metadata": {},
   "source": [
    "Afin de simplifier la dimension de notre dataframe et déduire de potentiels liens entre les taux de chargement et le , on souhaite réaliser une Analyse en composantes principales (ACP). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8b563a",
   "metadata": {},
   "source": [
    "Comme précédemment, il n'est pas nécessaire de standardiser les données car celles-ci sont comprises entre 0 et 1 en tant que taux de chargement. Il n'est donc pas nécessaire de standardiser les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535e91d5-f6e0-48d0-865d-72a0669bcb12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Création du nouveau dataset \n",
    "\n",
    "#Etape 1: \n",
    "# Calcul des moyennes pour chaque heure de la journée\n",
    "minuit_am = loading.iloc[:, [0, 24, 48, 72, 96, 120, 144]].mean(axis=1)\n",
    "une_am = loading.iloc[:, [1, 25, 49, 73, 97, 121, 145]].mean(axis=1)\n",
    "deux_am = loading.iloc[:, [2, 26, 50, 74, 98, 122, 146]].mean(axis=1)\n",
    "trois_am = loading.iloc[:, [3, 27, 51, 75, 99, 123, 147]].mean(axis=1)\n",
    "quatre_am = loading.iloc[:, [4, 28, 52, 76, 100, 124, 148]].mean(axis=1)\n",
    "cinq_am = loading.iloc[:, [5, 29, 53, 77, 101, 125, 149]].mean(axis=1)\n",
    "six_am = loading.iloc[:, [6, 30, 54, 78, 102, 126, 150]].mean(axis=1)\n",
    "sept_am = loading.iloc[:, [7, 31, 55, 79, 103, 127, 151]].mean(axis=1)\n",
    "huit_am = loading.iloc[:, [8, 32, 56, 80, 104, 128, 152]].mean(axis=1)\n",
    "neuf_am = loading.iloc[:, [9, 33, 57, 81, 105, 129, 153]].mean(axis=1)\n",
    "dix_am = loading.iloc[:, [10, 34, 58, 82, 106, 130, 154]].mean(axis=1)\n",
    "onze_am = loading.iloc[:, [11, 35, 59, 83, 107, 131, 155]].mean(axis=1)\n",
    "minuit_pm = loading.iloc[:, [12, 36, 60, 84, 108, 132, 156]].mean(axis=1)\n",
    "une_pm = loading.iloc[:, [13, 37, 61, 85, 109, 133, 157]].mean(axis=1)\n",
    "deux_pm = loading.iloc[:, [14, 38, 62, 86, 110, 134, 158]].mean(axis=1)\n",
    "trois_pm = loading.iloc[:, [15, 39, 63, 87, 111, 135, 159]].mean(axis=1)\n",
    "quatre_pm = loading.iloc[:, [16, 40, 64, 88, 112, 136, 160]].mean(axis=1)\n",
    "cinq_pm = loading.iloc[:, [17, 41, 65, 89, 113, 137, 161]].mean(axis=1)\n",
    "six_pm = loading.iloc[:, [18, 42, 66, 90, 114, 138, 162]].mean(axis=1)\n",
    "sept_pm = loading.iloc[:, [19, 43, 67, 91, 115, 139, 163]].mean(axis=1)\n",
    "huit_pm = loading.iloc[:, [20, 44, 68, 92, 116, 140, 164]].mean(axis=1)\n",
    "neuf_pm = loading.iloc[:, [21, 45, 69, 93, 117, 141, 165]].mean(axis=1)\n",
    "dix_pm = loading.iloc[:, [22, 46, 70, 94, 118, 142, 166]].mean(axis=1)\n",
    "onze_pm = loading.iloc[:, [23, 47, 71, 95, 119, 143, 167]].mean(axis=1)\n",
    "\n",
    "#Etape 2 : on forme le jeu de données \n",
    "# Création du nouveau DataFrame\n",
    "data_heures = pd.DataFrame({\n",
    "    'Minuit': minuit_am,\n",
    "    '1h': une_am,\n",
    "    '2h': deux_am,\n",
    "    '3h': trois_am,\n",
    "    '4h': quatre_am,\n",
    "    '5h': cinq_am,\n",
    "    '6h': six_am,\n",
    "    '7h': sept_am,\n",
    "    '8h': huit_am,\n",
    "    '9h': neuf_am,\n",
    "    '10h': dix_am,\n",
    "    '11h': onze_am,\n",
    "    '12h': minuit_pm,\n",
    "    '13h': une_pm,\n",
    "    '14h': deux_pm,\n",
    "    '15h': trois_pm,\n",
    "    '16h': quatre_pm,\n",
    "    '17h': cinq_pm,\n",
    "    '18h': six_pm,\n",
    "    '19h': sept_pm,\n",
    "    '20h': huit_pm,\n",
    "    '21h': neuf_pm,\n",
    "    '22h': dix_pm,\n",
    "    '23h': onze_pm\n",
    "})\n",
    "\n",
    "data_heures['Hill'] = coord['bonus']\n",
    "\n",
    "print(data_heures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04136c73-5271-47e7-a772-129b9ccf240c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca_3 = PCA()\n",
    "data_heures_pca = pca_3.fit_transform(data_heures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a07f39a-5d1e-4c08-956e-f3fdf27cba47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#On affiche la variance expliquée par les composantes de l'ACP\n",
    "plt.plot(np.cumsum(pca_3.explained_variance_ratio_))\n",
    "\n",
    "plt.title('Variance cumulée expliquée en fonction de la dimension de l espace de l`ACP')\n",
    "plt.xlabel('Nombre de composantes dans l ACP')\n",
    "plt.ylabel('Variance cumulée expliquée')\n",
    "\n",
    "#On regarde le nombre de composantes nécessaires pour expliquer 90 % de la variance \n",
    "pca_3 = PCA(0.90).fit(data_heures) \n",
    "pca_3.n_components_ \n",
    "print(f\"on garde {pca_3.n_components_} composantes pour le PCA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521c40a7",
   "metadata": {},
   "source": [
    "La fonction nous dit qu'il faut garder 3 composantes pour expliquer 90% de la variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0ab7a3-ec65-41b4-b58f-d2d7dcb7e6ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#On réalise l'ACP pour 3 composantes\n",
    "pca_3 = PCA(n_components = 3)\n",
    "data_heures_pca = pca_3.fit_transform(data_heures) \n",
    "\n",
    "print(100*pca_3.explained_variance_ratio_)\n",
    "\n",
    "#Affichage et vérification de la dimension du jeu de données avant et après ACP\n",
    "print('--- PCA ---')\n",
    "print('Dimension initiale :' , data_heures.shape)\n",
    "print('Dimension après projection:', data_heures_pca.shape)\n",
    "\n",
    "print('')\n",
    "\n",
    "print('--- Variance expliquée  ---')\n",
    "print('Composante 1:', round(pca.explained_variance_[0],2), 'i.e.', round(100*pca.explained_variance_ratio_[0],2), '% de la variance totale')\n",
    "print('Composante 2:', round(pca.explained_variance_[1],2), 'i.e.', round(100*pca.explained_variance_ratio_[1],2), '% de la variance totale')\n",
    "print('Composante 3:', round(pca.explained_variance_[2],2), 'i.e.', round(100*pca.explained_variance_ratio_[2],2), '% de la variance totale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ac4d0a-c149-4499-af28-173447127bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Affichage des bar plot de la proportion d'explication de la variance par chaque composante de l'ACP\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=[f\"PC{i+1}\" for i in range(len(pca_3.explained_variance_ratio_))], y=pca_3.explained_variance_ratio_ * 100)\n",
    "plt.xlabel(\"Composantes Principales\")\n",
    "plt.ylabel(\"Pourcentage de Variance Expliquée\")\n",
    "plt.title(\"Proportion de Variance Expliquée par Chaque Composante Principale\")\n",
    "plt.ylim(0,80) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3cca88-3957-4318-99f7-e8b2d88a4be9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Affichage des boxplot des composantes de l'ACP\n",
    "box = plt.boxplot(data_heures_pca[:,:10], patch_artist=True)\n",
    "plt.setp(box[\"boxes\"], facecolor=\"coral\", alpha=.5)\n",
    "plt.title(\"Box plots des 3 premières composantes\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd81d143",
   "metadata": {},
   "source": [
    "On projette les données triées par heures sur les deux premiers axes de l'ACP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e897c6b9-6f74-486d-942b-0661f42ba4f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coord1 = pca.components_[0] * np.sqrt(pca_3.explained_variance_[0])\n",
    "coord2 = pca.components_[1] * np.sqrt(pca_3.explained_variance_[1])\n",
    "\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "for i, j, nom in zip(coord1, coord2, data_heures.columns):\n",
    "    plt.text(i, j, nom, fontsize=10)\n",
    "    plt.arrow(0, 0, i, j, color = 'purple', alpha=0.7, width = 0.0001)\n",
    "\n",
    "plt.axis((-0.2, 0.2, -0.2, 0.2))\n",
    "plt.gcf().gca().add_artist(plt.Circle((0, 0), radius = 0.2, color = 'cornflowerblue', fill = False))\n",
    "\n",
    "plt.title('Carte de projection - PCA')\n",
    "plt.xlabel('Composante principale 1')\n",
    "plt.ylabel('Composante principale 2')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868a9779",
   "metadata": {},
   "source": [
    "On projette les données triées par heures sur l'axes 1 et 3 de l'ACP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4dbcf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coord1 = pca.components_[0] * np.sqrt(pca_3.explained_variance_[0])\n",
    "coord2 = pca.components_[2] * np.sqrt(pca_3.explained_variance_[2])\n",
    "\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "for i, j, nom in zip(coord1, coord2, data_heures.columns):\n",
    "    plt.text(i, j, nom, fontsize=10)\n",
    "    plt.arrow(0, 0, i, j, color = 'purple', alpha=0.7, width = 0.0001)\n",
    "\n",
    "plt.axis((-0.2, 0.2, -0.2, 0.2))\n",
    "plt.gcf().gca().add_artist(plt.Circle((0, 0), radius = 0.2, color = 'cornflowerblue', fill = False))\n",
    "\n",
    "plt.title('Carte de projection - PCA')\n",
    "plt.xlabel('Composante principale 1')\n",
    "plt.ylabel('Composante principale 3')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30862812-2be8-4d77-9913-74144c84a4f0",
   "metadata": {},
   "source": [
    "On projette les données triées par heures sur l'axes 2 et 3 de l'ACP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d142240",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord1 = pca.components_[1] * np.sqrt(pca_3.explained_variance_[1])\n",
    "coord2 = pca.components_[2] * np.sqrt(pca_3.explained_variance_[2])\n",
    "\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "for i, j, nom in zip(coord1, coord2, data_heures.columns):\n",
    "    plt.text(i, j, nom, fontsize=10)\n",
    "    plt.arrow(0, 0, i, j, color = 'purple', alpha=0.7, width = 0.0001)\n",
    "\n",
    "plt.axis((-0.15, 0.15, -0.15, 0.15))\n",
    "plt.gcf().gca().add_artist(plt.Circle((0, 0), radius = 0.15, color = 'cornflowerblue', fill = False))\n",
    "\n",
    "plt.title('Carte de projection - PCA')\n",
    "plt.xlabel('Composante principale 1')\n",
    "plt.ylabel('Composante principale 3')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a2513b",
   "metadata": {},
   "source": [
    "ANALYSE : \n",
    "Voir le graphe des variables en R.\n",
    "\n",
    "Dans ce nouveau dataset et grâce aux projections dans les plans d'ACP, on peut faire les hypothèses suivantes : \n",
    "- la composante 1 semble toujours représenter le chargement des stations.\n",
    "- la composante 2 semble elle correspondre aux heures de nuit et de jour. \n",
    "- la composante 3 semble évoquer les heures ou le chargement varie le plus, mais les variables ne sont pas bien projetées donc cela reste à nuancer. \n",
    "\n",
    "Les variables sont mieux projetées sur la dimension 2 en utilisant ce jeu de données que celui par jour. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4218b40f-aee9-4906-856c-83c43288fd6e",
   "metadata": {},
   "source": [
    "#### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dd9e45-7cf4-471a-a91f-f2381df4d79f",
   "metadata": {},
   "source": [
    "#### 5.1.1. Méthode de clustering avec k-means\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9807a8-dab3-411c-b811-2896c9875bbf",
   "metadata": {},
   "source": [
    "L'algorithme K-Means est une technique de classification non-supervisée des données. Il cherche à minimiser les distances entre les observations et les centres des clusters auxquels elles appartiennent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30127fd-6bb2-4a38-b1f4-42b4028de803",
   "metadata": {},
   "source": [
    "Tout d'abord, on va effectuer l'algorithme K-Means sur le jeu de données complet 'data_heures' et voir si on peut en tirer quelques interprétations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401d5cba-7362-4bf1-9b6e-c09c15449be1",
   "metadata": {
    "tags": []
   },
   "source": [
    "On va déterminer le nombre de clusters optimal grace à la méthode du coude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a96004-12e5-4663-8b94-e9598dcbcf24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inertia = []\n",
    "for k in range(1, 15):\n",
    "    kmeans_heures = KMeans(n_clusters=k, init='random', n_init='auto', max_iter=100, random_state=42)\n",
    "    kmeans_heures.fit(data_heures )\n",
    "    inertia.append(kmeans_heures.inertia_)\n",
    "inertia = np.array(inertia)\n",
    "\n",
    "\n",
    "plt.scatter(range(2, 15), inertia[1:])\n",
    "plt.xlabel('nombre de clusters', fontsize = 15)\n",
    "plt.ylabel('inertie', fontsize = 15)\n",
    "plt.title(\"Graphe du coude\", fontsize = 15)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- #\n",
    "\n",
    "\n",
    "# Using yellowbrick\n",
    "\n",
    "kmeans_heures = KMeans(init='random', n_init='auto', max_iter=100, random_state=42)\n",
    "visualizer = KElbowVisualizer(kmeans_heures, k=(1,12))\n",
    "\n",
    "visualizer.fit(data_heures )    # Fit the data to the visualizer\n",
    "visualizer.show()    # Finalize and render the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae704a7-fb8b-434a-b5b2-a3583e40b363",
   "metadata": {},
   "source": [
    "Comme pour l'analyse des autres jeux de données, le nombre de clusters idéal est 4. Avec les graphes de scores silhouettes suivantt on peut valider ce résultat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4157956-1454-4def-b4e1-8a4cf38a53c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(15,8))\n",
    "\n",
    "for k in range(2, 6):\n",
    "    kmeans_heures = KMeans(n_clusters=k, init='random', n_init='auto', max_iter=100, random_state=42)\n",
    "    q, mod = divmod(k, 2) \n",
    "    # Create SilhouetteVisualizer instance with KMeans instance\n",
    "    visualizer = SilhouetteVisualizer(kmeans_heures, colors='yellowbrick', ax=ax[q-1][mod])\n",
    "    visualizer.fit(data_heures )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5679a91-3f0b-4f69-96a2-41a3e6e22f3e",
   "metadata": {},
   "source": [
    "En effet, le choix d'un nombre de cluster de 4 semble optimal car le score silhouette associé ne possède quasi pas de valeurs négatives et toutes les bandes dépassent le trait rouge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59e93cf-ba5e-4a27-91f8-9e7e847bdb07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "K = 4\n",
    "kmeans_heures = KMeans(n_clusters=K, init='random', n_init='auto', random_state=0)\n",
    "clusters_heures = kmeans_heures.fit_predict(data_heures)\n",
    "#On fixe le nombre de clusters à 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bf0604-e82c-437c-80fd-674bd24906e8",
   "metadata": {},
   "source": [
    "Observons mainteant la répartition des valeurs dans chaque cluster. Pour voir si certains clusters sont plus importants que d'autres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1603d219-bc0d-46ec-9b02-a70402102039",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('Set3',K)\n",
    "plt.bar(*np.unique(clusters_heures, return_counts=True), color=cmap.colors)\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cdda1d-4736-4fe4-acc7-ab61064cfc6e",
   "metadata": {},
   "source": [
    "Les valeurs sont réparties équitablement dans les clusters 1, 2 et 4 à la différence du 3 qui possède davantage de valeurs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3515905d-4b84-4da8-b58a-be8950783b43",
   "metadata": {},
   "source": [
    "Avant de tirer des conclusions des analyses qui vont suivre, il faut vérifier que la variance intra-classe de chaque clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6688135-5905-4634-8fdb-88f10fd7b9c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# distance de chaque point de données à son centre de cluster\n",
    "distances = kmeans_heures.transform(data_heures)\n",
    "\n",
    "#variance intraclasse pour chaque cluster\n",
    "variances = []\n",
    "for cluster in range(kmeans_heures.n_clusters):\n",
    "    cluster_distances = distances[kmeans_heures.labels_ == cluster, cluster]\n",
    "    variance = np.var(cluster_distances)\n",
    "    variances.append(variance)\n",
    "\n",
    "# Affichage\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(range(kmeans_heures.n_clusters), variances, color='skyblue')\n",
    "plt.xlabel('Clusters')\n",
    "plt.ylabel('Variance intra-classe')\n",
    "plt.title('Variance intra-classe par cluster')\n",
    "plt.xticks(range(kmeans_heures.n_clusters), [f'Cluster {i+1}' for i in range(kmeans_heures.n_clusters)])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ffcbfd-7b02-4c74-9cf6-0503e028a8b7",
   "metadata": {},
   "source": [
    "On voit que la variance des clusters est raisonnable, nous pouvons continuer nos analyses. <br>\n",
    "On affiche maintenant les boxplots qui illustre la répartition des distances de chaque point au centre de son cluster. Nous allons vérifier que cette distribution est dans une fenêtre assez réduite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f69b22-1c2c-4138-8aab-b8c47d8dc4f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculer les distances de chaque point de données à son centre de cluster\n",
    "distances = kmeans_heures.transform(pd.DataFrame(data_heures))\n",
    "\n",
    "# Créer une liste de distances pour chaque cluster\n",
    "distances_per_cluster = [[] for _ in range(kmeans_heures.n_clusters)]\n",
    "for cluster in range(kmeans_heures.n_clusters):\n",
    "    cluster_distances = distances[kmeans_heures.labels_ == cluster, cluster]\n",
    "    distances_per_cluster[cluster] = cluster_distances\n",
    "\n",
    "# Plotter les boxplots\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(distances_per_cluster, patch_artist=True, labels=[f'Cluster {i+1}' for i in range(kmeans_heures.n_clusters)])\n",
    "plt.xlabel('Clusters')\n",
    "plt.ylabel('Distance au centre de cluster')\n",
    "plt.title('Distribution des distances au centre de cluster')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94849e5-af1c-4bc5-81be-4f714973c292",
   "metadata": {
    "tags": []
   },
   "source": [
    "On voit que les boxplots ne sont pas très larges, on peut donc continuer nos analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25df746-c393-4562-8e22-77db7c1fc947",
   "metadata": {},
   "source": [
    "On va afficher maintenant le chargement moyen des stations par cluster au cours de la semaine. Cela va peut-être nous permettre de visualiser des tendances communes entre les éléments d'un même cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bde0ea2-9f53-4d43-bcef-6e2c56e2bec0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loading_sub5 = loading.iloc[:,:]\n",
    "loading_sub5['cluster']=clusters_heures\n",
    "mean_loading5=loading_sub5.groupby('cluster').mean()\n",
    "mean_loading5.head()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "col= ['#FF69B4', '#008080'  ,'#800080','#FFFF00']\n",
    "\n",
    "# Affichage des 4 lignes sur le même graphique\n",
    "\n",
    "for i in range(4):\n",
    "    ax.plot(mean_loading5.columns, mean_loading5.iloc[i], label=f'Cluster {i+1}',color=col[i])\n",
    "\n",
    "    \n",
    "plt.legend()\n",
    "plt.title('Moyenne des chargements par cluster')\n",
    "plt.xlabel('Temps en heures')\n",
    "plt.ylabel('Moyenne des loading')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d095627-2c2e-4ec9-9d6b-2fd724ef0d63",
   "metadata": {},
   "source": [
    "Les tendances de courbes du chargement moyen de data_heures sont similaires à celles obtenues lors de l'étude de loading.\n",
    "On retrouve un cluster qui à tendance à se vider le matin et à se remplir à nouveau le soir. Le second cluster correspond aux stations qui se chargent aussi le matin et se remplissent le soir mais qui auront tendances à rester assez remplies. \n",
    "Ensuite, on retrouve un cluster qui se charge la journée et se décharge la nuit. Le 4ème à un comportement similaire mais est plus souvent vide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3862e6-37d7-49a9-88bd-140906d5368c",
   "metadata": {},
   "source": [
    "Nous allons vérifier que pour ce jeu de donnée également, il y a un lien entre la variable 'hill' et les clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efdf481-0298-4113-ba76-771c351f9d95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tbl4_1 = pd.crosstab(clusters_heures, coord['bonus'])\n",
    "\n",
    "#on affiche la mosaïque :\n",
    "tbl4_1.index = ['Cluster_1', 'Cluster_2', 'Cluster_3','Cluster_4'] \n",
    "tbl4_1.columns = ['Pas colline', 'Colline']  \n",
    "\n",
    "sns.heatmap(tbl4_1, cmap='coolwarm', annot=True, fmt=\"d\")\n",
    "plt.title(\"Stations en altitude en fonction du clusters\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726e29e2-9c9a-49db-97bb-596e36b7dae2",
   "metadata": {},
   "source": [
    "A nouveau, on voit que les stations en altitudes sont toutes regroupées dans 1 seul cluster, celui qui corespond aux taux de chargement les plus bas comme précédemment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff684adf-623c-4321-b768-ff98b02ddf02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Etude sur data_heures_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936d4368-c9a9-4e95-b0d5-64cff9f07c25",
   "metadata": {},
   "source": [
    "Maintenant, on va effectuer l'algorithme K-Means à nouveau mais cette fois-ci, sur le jeu de données réduit par l'ACP. Cela va permettre de voir si les données réduites représentent bien le jeu de données complet. On cherche entre autre à voir si la classification réalisée sur le jeu de données complet et la même sur celui réduit, si c'est le cas cela nous permettra de simplifier les calculs des algorithmes suivants en travaillant sur le jeu de données réduit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab055774-4328-4c9a-8ef9-90870ec1e991",
   "metadata": {},
   "source": [
    "Déterminons le nombre de clusters optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa7f805-6b98-4584-924f-067c4b89df18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inertia = []\n",
    "for k in range(1, 15):\n",
    "    kmeans_PCA_heures = KMeans(n_clusters=k, init='k-means++', n_init='auto', max_iter=100, random_state=42)\n",
    "    kmeans_PCA_heures.fit(data_heures_pca )\n",
    "    inertia.append(kmeans_PCA_heures.inertia_)\n",
    "inertia = np.array(inertia)\n",
    "\n",
    "\n",
    "plt.scatter(range(2, 15), inertia[1:])\n",
    "plt.xlabel('nombre de clusters', fontsize = 15)\n",
    "plt.ylabel('inertie', fontsize = 15)\n",
    "plt.title(\"Graphe du coude\", fontsize = 15)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- #\n",
    "\n",
    "\n",
    "# avec yellowbrick\n",
    "\n",
    "kmeans_PCA_heures = KMeans(init='random', n_init='auto', max_iter=100, random_state=42)\n",
    "visualizer = KElbowVisualizer(kmeans_PCA_heures, k=(1,12))\n",
    "\n",
    "visualizer.fit(data_heures_pca)   \n",
    "visualizer.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2175ba4f-8ab2-4b5a-af3c-18dd464fb23a",
   "metadata": {},
   "source": [
    "Le coude est ici à 4. Vérifions maintenant ce résultat grace aux graphiques des scores silhouette."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd0ebb8-c20a-4db7-9c09-1c441b859497",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(15,8))\n",
    "\n",
    "for k in range(2, 6):\n",
    "    kmeans_PCA_heures = KMeans(n_clusters=k, init='random', n_init='auto', max_iter=100, random_state=42)\n",
    "    q, mod = divmod(k, 2) \n",
    "    # Create SilhouetteVisualizer instance with KMeans instance\n",
    "    visualizer = SilhouetteVisualizer(kmeans_PCA_heures, colors='yellowbrick', ax=ax[q-1][mod])\n",
    "    visualizer.fit(data_heures_pca )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1137c9f-93f2-42a7-a059-eb89ad09a7e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "Le résultat précédent est validé. Toutes les conditions nécessaires sont présentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee32ae76-5dc3-4f4f-9215-6d1a4cb0438c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "K = 4\n",
    "kmeans_PCA_heures = KMeans(n_clusters=K, init='random', n_init='auto', random_state=0)\n",
    "clusters_heures_pca = kmeans_PCA_heures.fit_predict(data_heures_pca )\n",
    "#On fixe le nombre de clusters à 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fa25e3-143f-4abd-9c52-c429b0c6f0c5",
   "metadata": {},
   "source": [
    "Quelles est la répartition des variables dans les clusters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9831593-4180-44f3-b30d-0282ec23dd5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('Set3',K)\n",
    "plt.bar(*np.unique(clusters_heures_pca, return_counts=True), color=cmap.colors)\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3816c5-5b43-476c-8946-68ed0cedad78",
   "metadata": {
    "tags": []
   },
   "source": [
    "Les données sont distribuées de la même facon que pour les données data_heures complètes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d86ae4-1893-4281-811f-e068a61e7b19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "#affichage du nuage de points des clusters identifiés par des couleurs différentes\n",
    "plt.scatter(data_heures_pca[:, 0], data_heures_pca[:, 1], c=clusters_heures_pca, cmap='viridis', s=50, alpha=0.5)\n",
    "legend_labels = ['Cluster 1', 'Cluster 2', 'Cluster 3', 'Cluster 4']  # Liste des étiquettes de légende pour chaque cluster\n",
    "legend_markers = [plt.Line2D([0], [0], linestyle='none', marker='o', color='#800080', markersize=10),\n",
    "                  plt.Line2D([0], [0], linestyle='none', marker='o', color='#008080', markersize=10),\n",
    "                  plt.Line2D([0], [0], linestyle='none', marker='o', color='#FFFF00', markersize=10),\n",
    "                  plt.Line2D([0], [0], linestyle='none', marker='o', color='#FF69B4', markersize=10)]\n",
    "\n",
    "plt.legend(legend_markers, legend_labels, loc='lower right')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('Clusters dans le plan de l\\'ACP')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d652313a-022e-4acd-bbbf-9e213c302bd0",
   "metadata": {
    "tags": []
   },
   "source": [
    "Ce graphe représente la répartition des données dans le plan de l'ACP (dim 1 et dim 2). On voit que les points sont bien réparties dans les clusters et qu'ils ne se mélangent pas.\\\n",
    "Les points du cluster de droite correspondent aux stations chargées en moyenne (car corrélées positivement avec la dimension 1) avec une variation faible (car peu corrélée selon la dimension 2).\n",
    "Les points du cluster de gauche correspondent aux stations peu chargées en moyenne (car corrélées négativement avec la dimension 1) avec une variation faible (car peu corrélée selon la dimension 2).\n",
    "Les points du cluster du haut correspondent aux stations fortement chargées la nuit (corrélées positivement avec la dimension 2) et peu chargées le jour.\n",
    "Les points du cluster du bas correspondent aux stations fortement chargées le jour (corrélées négativement avec la dimension 2) et peu chargées la nuit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83acf14-9e9c-4673-bfb2-7627b98109a2",
   "metadata": {},
   "source": [
    "Avant de tirer des conclusions des analyses qui vont suivre, il faut vérifier que la variance intra-classe de chaque clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67e8c51-3b72-4ef6-b60a-374e2e66d4df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# distance de chaque point de données à son centre de cluster\n",
    "distances = kmeans_PCA_heures.transform(data_heures_pca)\n",
    "\n",
    "#variance intraclasse pour chaque cluster\n",
    "variances = []\n",
    "for cluster in range(kmeans_PCA_heures.n_clusters):\n",
    "    cluster_distances = distances[kmeans_PCA_heures.labels_ == cluster, cluster]\n",
    "    variance = np.var(cluster_distances)\n",
    "    variances.append(variance)\n",
    "\n",
    "# Affichage\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(range(kmeans_PCA_heures.n_clusters), variances, color='skyblue')\n",
    "plt.xlabel('Clusters')\n",
    "plt.ylabel('Variance intra-classe')\n",
    "plt.title('Variance intra-classe par cluster')\n",
    "plt.xticks(range(kmeans_PCA_heures.n_clusters), [f'Cluster {i+1}' for i in range(kmeans_PCA_heures.n_clusters)])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17803945-d655-4458-a1b7-53d7dbfd2d63",
   "metadata": {},
   "source": [
    "Les variances sont raisonnables, on peut donc continuer nos analyses. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947a2184-bdfe-49fa-8163-420c74410d4e",
   "metadata": {},
   "source": [
    "Y-a-t-il un lien entre 'hill' et les clusters ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e79edc-5a74-472a-b629-6985bf79cf1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tbl4_2 = pd.crosstab(clusters_heures_pca, coord['bonus'])\n",
    "\n",
    "#on affiche la mosaïque :\n",
    "tbl4_2.index = ['Cluster_1', 'Cluster_2', 'Cluster_3','Cluster_4'] \n",
    "tbl4_2.columns = ['Pas colline', 'Colline']  \n",
    "\n",
    "sns.heatmap(tbl4_2, cmap='coolwarm', annot=True, fmt=\"d\")\n",
    "plt.title(\"Stations en altitude en fonction du clusters\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6548d700-1260-4d52-9dd2-5475cc16a836",
   "metadata": {},
   "source": [
    "Effectivement, les stations en altitudes sont regroupées dans un unique cluster comme pour tous les autres jeux de données, le cluster_3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a66aa5-c7a0-4634-8127-7f6a4fbab88f",
   "metadata": {},
   "source": [
    "On va afficher maintenant le chargement moyen des stations par cluster au cours de la semaine. Cela va peut-être nous permettre de visualiser des tendances communes entre les éléments d'un même cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f2f071-a41d-45fd-bf5e-2be361b87b21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loading_sub6 = loading.iloc[:,:]\n",
    "loading_sub6['cluster']=clusters_heures_pca\n",
    "mean_loading6=loading_sub6.groupby('cluster').mean()\n",
    "mean_loading6.head()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "col =  ['#FF69B4', '#008080'  ,'#800080','#FFFF00']\n",
    "\n",
    "# Affichage des 4 lignes sur le même graphique\n",
    "for i in range(4):\n",
    "    ax.plot(mean_loading6.columns, mean_loading6.iloc[i], label=f'Cluster {i+1}',color=col[i])\n",
    "\n",
    "    \n",
    "plt.legend()\n",
    "plt.title('Moyenne des chargements par cluster')\n",
    "plt.xlabel('Temps en heures')\n",
    "plt.ylabel('Moyenne des loading')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d7bacb-6dd4-4b17-aa86-58e9e3f41848",
   "metadata": {},
   "source": [
    "L'interprétation est la même que celle du jeu de données complet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14deafee-8f91-4af8-a6dd-243a44c1f981",
   "metadata": {},
   "source": [
    "Comparaison des 2 jeux de données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f82178-0f97-4985-bd08-5245023bc30f",
   "metadata": {},
   "source": [
    "On compare les deux classifications grâce à un scatterplot pour voir le nombre de valeurs qui correspondent dans le cas normal et le cas réduit, afin de voir si il est vraiment utile de faire son analyse sur l'ACP ou non  :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a8eddb-8261-440b-aa56-855ddacd36c1",
   "metadata": {},
   "source": [
    "Tout d'abord on reclasse les clusters pour qu'ils correspondent bien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7357864-123d-48b5-b381-9f56b261bf26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " cm3,res_pca_sorted = matchClasses(clusters_heures, clusters_heures_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c93fe71-085c-484a-9c0d-0d510647fd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "Position = np.array(coord)[:,0:2]\n",
    "\n",
    "#graphe à pour data_jours entier\n",
    "f1 = px.scatter_mapbox(clusters_heures, Position[:,1], Position[:,0], color=clusters_heures, color_continuous_scale=[(0, '#800080'), (0.5, '#008080'), (1, '#FFFF00')], \n",
    "                        size_max=15, zoom=10,mapbox_style=\"carto-positron\", opacity = .9,\n",
    "                        title = 'clusters données complètes')\n",
    "\n",
    "f1.show()\n",
    "\n",
    "#graphe à pour data_jours_pca\n",
    "f2 = px.scatter_mapbox(res_pca_sorted, Position[:,1], Position[:,0], color=res_pca_sorted, color_continuous_scale =[(0, '#800080'), (0.5, '#008080'), (1, '#FFFF00')], \n",
    "                        size_max=15, zoom=10,mapbox_style=\"carto-positron\", opacity = .9,\n",
    "                        title = 'clusters données pca')\n",
    "f2.show()\n",
    "\n",
    "\n",
    "\n",
    "points_diff = clusters_heures != res_pca_sorted\n",
    "\n",
    "# Calcul du nombre de points différents\n",
    "num_diff_points = np.sum(points_diff)\n",
    "\n",
    "# Calcul du pourcentage de réussite\n",
    "pourcentage_reussite = (1- num_diff_points / len(clusters_heures)) * 100\n",
    "\n",
    "# Affichage du résultat\n",
    "print(f\"Nombre de points différents : {num_diff_points} sur {len(clusters_heures)}\")\n",
    "print(f\"Pourcentage de réussite : {pourcentage_reussite:.2f}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f345adcc-66cb-4a24-b5f8-7b25b67b58fd",
   "metadata": {},
   "source": [
    "Le pourcentage de réussite montre que le clustering sur le jeu de données réduit représente bien le jeu de données complet. On peut donc utiliser le jeu réduit pour la suite des analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41418144-7259-495d-b41f-fadc32959dbd",
   "metadata": {},
   "source": [
    "On affiche la matrice de confusion pour vérifier ce résultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b1a86f-2a7a-428d-bd00-e9aa1d792c73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay(cm3).plot()\n",
    "plt.xlabel('Kmeans sur les données heures réduites (PCA)')\n",
    "plt.ylabel('Kmeans sur les données heures')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1af9be-c3fd-400c-8c9e-e4207d7a0cee",
   "metadata": {},
   "source": [
    "Le jeu de données complet et le jeu réduit ont des clusters qui correspondent bien, la  matrice est quasi diagonale. La conclusion est la même qu'au dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b0f29f-8fbf-459b-bca0-fa36de0e5b19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#on convertit la table de confusion en dataframe \n",
    "df_cm3 = pd.DataFrame(cm3, columns=['groupe0','groupe1', 'groupe2','groupe3'], index=['groupe_pca0', 'groupe_pca1', 'groupe_pca2', 'groupe pca3'])\n",
    "df_cm3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db7198f-2c9a-4fa1-83b5-8cc966a89c82",
   "metadata": {},
   "source": [
    "Ainsi, on vient de montrer que nos classifications Kmeans sur le jeu de données complets et réduits par la PCA formés des clusters similaires. Ce qui va nous permettre de travailler sur les données réduites pour la suite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6247d7-c38e-41ec-a202-b81bd8843144",
   "metadata": {},
   "source": [
    "#### 5.1.2. CAH : Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3484ad42-61da-4bf4-a488-8bf130594fb3",
   "metadata": {},
   "source": [
    "Etudions maintenant la méthode de la classification ascendante hiérarchique (CAH). Cette méthode consiste à afficher des dendrogrammes des différentes données en fonction de différents likages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6d9909-80fd-4644-a0e3-5828bc785dd1",
   "metadata": {},
   "source": [
    "Comme expliqué précedemment, on préférera faire l'analyse en prenant un échantillon plus petit pour minimiser les temps de calculs. Nous avons vu que l'analyse des données PCA donnait de bons résultats, donc pour faciliter les calculs, lors des analyses suivantes nous prendrons les données réduites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ada32d-7e52-443c-94b0-9c0250ca5ee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Dimension du jeu de données entier 'loading' :\",data_heures.shape)\n",
    "print(\"Dimension du jeu de données réduit 'loading_pca': \"  +str(data_heures_pca.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd36cce0-eafc-4314-9e40-a5fac0135b65",
   "metadata": {
    "tags": []
   },
   "source": [
    "On voit bien que la dimension est bien réduite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34fa1b8-ffaf-45d5-9628-6fd9892af38e",
   "metadata": {},
   "source": [
    "On détermine le nombre de clusters adéquats grâce au graphe du coude :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953e6d6a-6255-41f0-a1c1-a7a98289bfdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Réalisation du CAH avec le linkage 'Ward' \n",
    "ac = AgglomerativeClustering(linkage=\"ward\", compute_distances=True)\n",
    "clusters_cah3 = ac.fit_predict(data_heures_pca)\n",
    "\n",
    "#Affichage du nombre de clusters à garder\n",
    "ac = AgglomerativeClustering(linkage='ward', compute_distances=True)\n",
    "visualizer = KElbowVisualizer(ac, k=(1,12))\n",
    "visualizer.fit(data_heures_pca)  \n",
    "visualizer.show()   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491f5b79-1db9-464f-ba37-46d510dc7e2e",
   "metadata": {},
   "source": [
    "D'après les résultats graphiques obtenus en R et en Python, nous décidons de prendre 4 clusters différents.\n",
    "\n",
    "On affiche alors le dendrogramme associé en utilisant le linkage \"Ward\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02135c2e-23bc-41c1-88ed-ad7ad620afca",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Nombre de clusters choisi par les indicateurs \n",
    "K = 4\n",
    "\n",
    "#Réalisation du CAH avec le linkage 'Ward' & affichage du résultat en coupant à K = 4 clusters\n",
    "ac = AgglomerativeClustering(n_clusters=K, compute_distances=True, linkage='ward')\n",
    "clusterscah3 = ac.fit(data_heures_pca)\n",
    "\n",
    "children = ac.children_\n",
    "distances = ac.distances_\n",
    "n_observations = np.arange(2, children.shape[0]+2)\n",
    "linkage_matrix = np.c_[children, distances, n_observations]\n",
    "\n",
    "sch.dendrogram(linkage_matrix, labels=ac.labels_)\n",
    "\n",
    "# On coupe le dendrogramme à K=4 clusters\n",
    "max_d = .5*(ac.distances_[-K]+ac.distances_[-K+1])\n",
    "plt.axhline(y=max_d, c='k')\n",
    "\n",
    "plt.title(\"Dendrogramme avec le linkage Ward\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8284fa1-498d-4e88-91ea-f61c073ae7da",
   "metadata": {},
   "source": [
    "On affiche tous les types de linkages que l'on a étudié pour montrer que \"Ward\" est le type dont le graphe est le plus facile à explorer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4d81e3-3acb-4da9-ac4b-fb99ecf4bea6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Affichage des dendrogrammes avec les différents linkages afin de pouvoir voir les différences sur un même jeu de données\n",
    "plt.subplot(2,2,1)\n",
    "linkage_matrix_single = sch.linkage(data_heures_pca, method='single')\n",
    "sch.dendrogram(linkage_matrix_single)\n",
    "plt.title(\"Dendrogramme avec le linkage simple\")\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "linkage_matrix_complete = sch.linkage(data_heures_pca, method='complete')\n",
    "sch.dendrogram(linkage_matrix_complete)\n",
    "plt.title(\"Dendrogramme avec le linkage complete\")\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "linkage_matrix_average = sch.linkage(data_heures_pca, method='average')\n",
    "sch.dendrogram(linkage_matrix_average)\n",
    "plt.title(\"Dendrogramme avec le linkage moyenne\")\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "linkage_matrix_ward = sch.linkage(data_heures_pca, method='ward')\n",
    "sch.dendrogram(linkage_matrix_ward)\n",
    "plt.title(\"Dendrogramme avec le linkage Ward\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6331a3c",
   "metadata": {},
   "source": [
    "De plus, on voit bien graphiquement que 3 clusters correspond bien au 'jump' le plus important dans le graphe de 'Ward'. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd841dd8-df77-4370-89c7-cf3eb69a2831",
   "metadata": {},
   "source": [
    "Enfin, la mosaïque sur R nous informe quele cluster_3 comporte le plus de stations situées sur des collines mais les autres clusters en contiennent également une bonne quantité donc on ne peut pas faire de liens explicites entre collines et clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dc6446-e869-4bb1-807c-3ce8e719dfb5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 5.1.3. Gaussian Mixture Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378ede8b-ecb6-4463-be5d-4ca2ac175c34",
   "metadata": {},
   "source": [
    "On peut utiliser les données issues de l'ACP car elle résume bien le jeu de donnée divisées par les heures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96505e3c-e845-4507-b1f3-dadc44c02ecb",
   "metadata": {},
   "source": [
    "Afin de mettre en place la méthode du GMM, on applique un critère de sélection du nombre de clusters. On choisit ici de travailler avec le crière BIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cb0c26-4e4b-499b-acf5-b37b717df1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Critère BIC :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d63503-f445-4708-97f2-0c27d6883a4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "k_max = 15\n",
    "\n",
    "bic = []\n",
    "for k in range(2, k_max):\n",
    "    gmm = GaussianMixture(n_components=k, init_params='kmeans', n_init=3)\n",
    "    gmm.fit(data_heures_pca)\n",
    "    bic.append(gmm.bic(data_heures_pca))\n",
    "bic = np.array(bic)\n",
    "\n",
    "plt.scatter(range(2, k_max), bic)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077716d3-901e-4108-a700-64f0b700883e",
   "metadata": {},
   "source": [
    "En appliquant le critère BIC en Python on devrait garder entre 6 et 8 variables. En R on trouve aussi qu'il faudrait garder 8 variables, mais le critère ne varie plus vraiment après 4 clusters. \n",
    "\n",
    "Prendre 8 clusters ne conviendrait pas à l'interprétation que l'on cherche à réaliser sur ceux-ci. On décide donc de prendre le risque de garder le même nombre de clusters qu'avec Kmeans c'est à dire 4. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84ef88e-64c1-4187-80f8-fa6b16eddaf8",
   "metadata": {},
   "source": [
    "On affiche d'abord la dispersion des points par cluster initiée par le modèle de mélange gaussien (GMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ef5d02-49ac-46ed-910e-e149d165643e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "K = 4\n",
    "cmap = plt.get_cmap('Set3', K)\n",
    "\n",
    "gmm = GaussianMixture(n_components=K, n_init=3)\n",
    "clusters_gmm_heures = gmm.fit_predict(data_heures_pca)\n",
    "\n",
    "# --- #\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "scatter = plt.scatter(data_heures_pca[:,0], data_heures_pca[:,1], c=clusters_gmm_heures, s=1, linewidths=1, cmap='viridis')\n",
    "\n",
    "legend_labels = [f'Cluster {i+1}' for i in range(4)]\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=legend_labels)\n",
    "    \n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8be6512-3888-4be3-8f64-cdafe3a819fd",
   "metadata": {},
   "source": [
    "Avant de continuer nos analyses\n",
    ", on va vérifier que la variance dans chaque cluster ne soit pas trop grande, ainsi les élèments d'un même cluster se comporteraient en moyenne de la même manière. <br> On affiche pour cela les boxplots des données de chaque cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f336083a-6344-4435-8f16-e4e7c2e33154",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aux = pd.DataFrame({\n",
    "    'label': ['Cluster ' + str(label) for label in clusters_gmm_heures],\n",
    "    'proba': np.max(gmm.predict_proba(data_heures_pca), axis=1)\n",
    "})\n",
    "sns.boxplot(x='label', y='proba', data=aux, palette='Set3', showfliers=False)\n",
    "plt.title('Cluster Probabilities')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741bb08d-c24e-4946-b144-341dd946da71",
   "metadata": {},
   "source": [
    "Les variances des données dans chaque cluster, représentée par la longueur des boxplots, est relativement faible, on peut continuer nos analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1ed14e-ef47-4c40-928b-3b3d9027e258",
   "metadata": {},
   "source": [
    "On affiche maintenant le chargement moyen des stations par clusters (issus de GMM) au cours de la semaine. Cela va peut-être nous permettre de visualiser des tendances communes entre les éléments d'un même cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6708d5-ddc8-49f6-92ba-59ba59aec7c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loading_sub5_1 = loading.iloc[:,:]\n",
    "loading_sub5_1['cluster']=clusters_gmm_heures\n",
    "mean_loading5=loading_sub5_1.groupby('cluster').mean()\n",
    "mean_loading5.head()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "col= ['purple', 'blue' ,'green','yellow']\n",
    "\n",
    "# Affichage des 4 lignes sur le même graphique\n",
    "\n",
    "for i in range(4):\n",
    "    ax.plot(mean_loading5.columns, mean_loading5.iloc[i], label=f'Cluster {i+1}',color=col[i])\n",
    "\n",
    "    \n",
    "plt.legend()\n",
    "plt.title('Moyenne des chargements par cluster')\n",
    "plt.xlabel('Temps en heures')\n",
    "plt.ylabel('Moyenne des loading')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ad5ded-3dde-402e-9f16-e518ac237d82",
   "metadata": {},
   "source": [
    "On affiche désormais le plot mosaïque, qui permet de voir combien de stations de chaque cluster sont en altitude ou non:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bc4acd-548e-4e9c-83d8-44de4a9e1a09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tbl3_3 = pd.crosstab(clusters_gmm_heures, coord['bonus'])\n",
    "\n",
    "#on affiche la mosaïque :\n",
    "tbl3_3.index = ['Cluster_1', 'Cluster_2', 'Cluster_3','Cluster_4'] \n",
    "tbl3_3.columns = ['Pas colline', 'Colline']  \n",
    "\n",
    "sns.heatmap(tbl3_3, cmap='coolwarm', annot=True, fmt=\"d\")\n",
    "plt.title(\"Stations en altitude en fonction du clusters\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c55cbf7-8426-4f00-948d-f400e9090b11",
   "metadata": {},
   "source": [
    "Analyse des divers graphes affichés précédement :\n",
    "\n",
    "Le graphe des moyennes nous montre que les tendances des courbes sont similaires à celles obtenues lors de l'étude de loading.\n",
    "On retrouve un cluster qui à tendance à se vider le matin et à se remplir à nouveau le soir. Le second cluster correspond aux stations qui se chargent aussi le matin et se remplissent le soir mais qui auront tendances à rester assez remplies. \n",
    "Ensuite, on retrouve un cluster qui se charge la journée et se décharge la nuit. Le 4ème à un comportement similaire mais est plus souvent vide.\n",
    "\n",
    "\n",
    "La mosaïque nous permet de voit qu'un cluster contient la majorité des stations en altitude, ce qui s'accorde avec notre interprétation du graphe des moyennes, concernant les stations qui sont moins chargées car situées sur des collines.\n",
    "\n",
    "On affiche le biplot qui affiche les clusters de GMM dans le plan d'ACP en R (seulement car la qualité du graphe en Python n'est vraiment pas satisfaisante). Ce graphe nous permet de voir que les points situés positivement sur l'axe de la composante 1 correspondent aux stations fortement chargées (par rapport à l'analyse de l'ACP faites précédemment (composante 1 ~ chargement des stations)). Les points du cluster situé vers l'origine du graphe correspondent aux stations moyennement chargées. Et les points situés négativement sur l'axe de la composante 1 correspondent aux stations peu chargées. Les trois clusters de la méthode GMM semblent donc correspondre aux niveaux de chargement des stations par rapport à la composante 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed34b2b6-2f84-49a1-a580-c6676b5ccec0",
   "metadata": {},
   "source": [
    "Comparons les  méthodes de classification Kmeans et GMM : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c89f90-01fb-4ca3-913a-9f7019fd53f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm3_GMM, clusters_pca_sorted_heures_GMM = matchClasses(clusters_gmm_heures, clusters_heures_pca)\n",
    "\n",
    "\n",
    "ConfusionMatrixDisplay(cm3_GMM).plot()\n",
    "\n",
    "plt.xlabel('Gmm sur les données heures réduites')\n",
    "plt.ylabel('Kmeans sur les données heures réduites (PCA)')\n",
    "plt.show()\n",
    "\n",
    "df_kmeans_gmm3 = pd.DataFrame(cm3_GMM, columns=['groupe0', 'groupe1','groupe2', 'groupe3'], index=['groupe_pca0', 'groupe_pca1','groupe_pca2', 'groupe_pca3'])\n",
    "df_kmeans_gmm3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7c1189-c333-4c1d-8032-247a7b6c311e",
   "metadata": {},
   "source": [
    "En affichant la table de contingence, on voit que le nombre de stations mal classifié est très faible, cela nous permet de conclure (directement et non en passant par une CA) que nos méthodes de classification sont comparables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bdb5a0-9ed4-4b2d-a120-f5c03a8d9b83",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. MCA sur data_heures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15876286-a328-4471-ab78-ba6880570097",
   "metadata": {},
   "source": [
    "Dans cette partie nous allons effectuer une MCA (Analyse par Correspondances Multiples). Son but est d'établir des correspondances entre des variables catégorielles (donc des variables qualitatives). La MCA va permettre de visualiser les relations entre ces variables pour ensuite créer des groupes sous-jacents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0675e7df-12e3-4180-9b93-6a9ef649f9ab",
   "metadata": {},
   "source": [
    "### 6.1. MCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0768470e-b379-4cec-82e9-6a0009339866",
   "metadata": {
    "tags": []
   },
   "source": [
    "Avant d'appliquer la MCA, il faut seuiller nos données, car celles-ci sont continues (data_heures), il nous les faut transformer en données qualitatives pour pouvoir faire notre analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959481f4-c1e7-4115-9987-cd1eb612b254",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Définition des intervalles\n",
    "intervalles = [0, 0.2, 0.6, 1]\n",
    "\n",
    "# Noms des seuils:\n",
    "noms_des_seuils = ['-', '=', '+']\n",
    "\n",
    "#nouveau data_frame :\n",
    "loading_quali_heures = data_heures.copy(deep=True)\n",
    "\n",
    "# Transformation des données continues en catégories avec des noms spécifiques\n",
    "for colonne in loading_quali_heures.columns :\n",
    "    loading_quali_heures[colonne] = pd.cut(loading_quali_heures[colonne], bins=intervalles, labels=noms_des_seuils, include_lowest=True)\n",
    "\n",
    "# Rajout d'une colonne pour signaler l'altitude\n",
    "loading_quali_heures['Hill'] = coord['bonus'].map({0: 'FAUX', 1: 'VRAI'})\n",
    "\n",
    "display(loading_quali_heures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fcf366-1662-407d-bf5d-e1db5f75a575",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calcul MCA\n",
    "mca3 = prince.MCA(\n",
    "    n_components=21,  # Le nombre de composantes voulues pour l'AMC\n",
    "    n_iter=10,  \n",
    "    copy=True,  \n",
    "    check_input=True, \n",
    "    engine='sklearn',  \n",
    "    random_state=42  \n",
    ")\n",
    "\n",
    "# Adapter le modèle \n",
    "mca3 = mca3.fit(loading_quali_heures)\n",
    "\n",
    "# Transformer les données\n",
    "loading_heures_mca = mca3.transform(loading_quali_heures)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(loading_heures_mca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab2e5a8-a76d-40dc-83e1-1c10d0289630",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## inertie portée par chaque composante\n",
    "display(mca3.eigenvalues_summary)\n",
    "mca3.scree_plot ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545d8b89-c0ff-4364-82ba-653ae5360074",
   "metadata": {},
   "source": [
    "D'après les résultats précédents, pour expliquer 80% de la variance il faudrait garder 7 composantes de l'AMC. Ce résultat se retrouve ici, dans le graphique suivant où l'on observe un changement de tendance de la courbe entre 6 et 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b11db2d-33cb-4a62-aa66-f4273b9d519b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualisation du graphe du coude\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(mca3.eigenvalues_) + 1), mca3.eigenvalues_, 'o-', color='pink')\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Dimensions')\n",
    "plt.ylabel('Valeurs Propres')\n",
    "plt.xticks(range(1, len(mca3.eigenvalues_) + 1))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42763f05-6cc6-4652-8838-9d77f3e15fbf",
   "metadata": {},
   "source": [
    "Dans le graphe précédent, par la méthode du coude on peut voir que le nombre de composantes idéal est entre 6 et 9. On choisit pour la suite 7 composantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dee872-acef-413c-8041-491c34f32378",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mca3 = prince.MCA(n_components = 7)\n",
    "mca3 = mca3.fit(loading_quali_heures)\n",
    "#On fixe le nombre de composantes à 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfce4723-8bb1-49b8-8683-244deb9afe7d",
   "metadata": {},
   "source": [
    "Regardons tout d'abord, si les variables sont bien représentées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8a47b6-11b7-4198-aaee-debe13348d07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Qualité de représentation\n",
    "mca3.column_cosine_similarities(loading_quali_heures)\n",
    "#afficher ce qui cos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c64dabb-57bf-4d32-9da0-e28fb45ed619",
   "metadata": {},
   "source": [
    "Ces valeurs vont de 0 (moins bonne représentation) à 1. Pour les composantes 0, 1 et 2 les valeurs du cos2 sont plutot importantes donc on peut dire que oui, les variables sont bien représentées dans le plan d'AMC 0, 1 et 2. Mais on rappelle que ces 3 composantes expliquent seulement 55% de variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bbef32-2b5f-42ca-91c4-a0544cb04a07",
   "metadata": {
    "tags": []
   },
   "source": [
    "On visualise ici la répartition résultats de la MCA dans le plan factoriel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2bf721-cc50-41c8-a4dc-908665f885ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mca3.plot(\n",
    "    loading_quali_heures,\n",
    "    x_component=0,\n",
    "    y_component=1,\n",
    "    show_column_markers=True,\n",
    "    show_row_markers=True,\n",
    "    show_column_labels=True,\n",
    "    show_row_labels=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c188a7e-fae4-44ab-8606-243aa2441985",
   "metadata": {},
   "source": [
    "On remarque ici que la variable 'Hill_vrai' est situé dans le plan MCA à coté de stations peu chargées en moyenne, elle est négativement corrélées à la dimension 0. Cela rejoint l'interprétation de la variable 'Hill' que nous avons depuis le debut du projet.\n",
    "De plus, on regarde que la composante 0 semble représenter le chargement moyen. Plus on est corrélé positivement, plus on est chargé en moyenne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d749cd-44f5-42e3-a6a4-0aa7798c614d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mca3.plot(\n",
    "    loading_quali_heures,\n",
    "    x_component=0,\n",
    "    y_component=2,\n",
    "    show_column_markers=True,\n",
    "    show_row_markers=True,\n",
    "    show_column_labels=True,\n",
    "    show_row_labels=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95c2697-ccf5-4386-b371-76e08e02b81d",
   "metadata": {},
   "source": [
    "Le graphe suivant va permerttre de visualiser les variables réduites par la MCA avec la variable 'Hill' dans le plan factoriel, on pourra peut etre trouver une tendance particulière."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e70b1f-b0d5-4107-a57d-611a3c60fa7f",
   "metadata": {},
   "source": [
    "Quelles variables contribuent le plus aux axes ? Trouve-t-on un comportement général ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d8abe5-0c92-46b4-a7f9-ee1588afe883",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "contrib3 = mca3.column_contributions_.style.format('{:.1%}')\n",
    "display(contrib3.highlight_max(color='orange').highlight_min(color='lightblue'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61b8bd1-71d3-4773-aa17-a861c2041ac8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "contrib3 = mca3.column_contributions_.iloc[:, :3]\n",
    "print(\"-------contribution > 0.025 pour comp0---------\")\n",
    "contrib3_C0 = contrib3.iloc[:, 0]\n",
    "C0_filtrée = contrib3_C0[contrib3_C0 > 0.025]\n",
    "display(C0_filtrée)\n",
    "\n",
    "print(\"-------contribution > 0.025 pour comp1---------\")\n",
    "contrib3_C1 = contrib3.iloc[:, 1]\n",
    "C1_filtrée = contrib3_C1[contrib3_C1 > 0.025]\n",
    "display(C1_filtrée)\n",
    "\n",
    "print(\"-------contribution > 0.025 pour comp2---------\")\n",
    "contrib3_C2 = contrib3.iloc[:, 2]\n",
    "C2_filtrée = contrib3_C2[contrib3_C2 > 0.025]\n",
    "display(C2_filtrée)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2772ac-e769-4822-9832-fb26d92239e9",
   "metadata": {},
   "source": [
    "On peut voir que pour la composante 0, c'est les heures de nuit chargées qui contribuent fortement. Pour la composante 1, plutôt les heures de journée chargées et celles de nuit faiblement chargées et pour la composante 2 les heures de nuits moyennement chargées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd3abed-e78a-491b-bfc2-2b287c2e1f30",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 6.2. Méthode de clustering K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e496d3be-4038-44f5-9737-232233d99c5c",
   "metadata": {},
   "source": [
    "Une fois l'analyse MCA faite, on va tenter de trouver des liens entre les variables, des comportements communs. Pour cela on effectue du clustering et plus précisement la méthode K-Means."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655cd3cf-5e36-43a0-a7fd-fa89acb2f729",
   "metadata": {},
   "source": [
    "On cherche tout d'abord le nombre de clusters optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d10b3-d1cb-46da-8864-9ccd4836cc42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inertia = []\n",
    "for k in range(1, 15):\n",
    "    kmeans_mca3 = KMeans(n_clusters=k, init='random', n_init='auto', max_iter=100, random_state=42)\n",
    "    kmeans_mca3.fit(loading_heures_mca)\n",
    "    inertia.append(kmeans_mca3.inertia_)\n",
    "\n",
    "inertia = np.array(inertia)\n",
    "\n",
    "\n",
    "plt.scatter(range(2, 15), inertia[1:])\n",
    "plt.xlabel('nombre de clusters', fontsize = 15)\n",
    "plt.ylabel('inertie', fontsize = 15)\n",
    "plt.title(\"Graphe du coude\", fontsize = 15)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- #\n",
    "\n",
    "\n",
    "# Using yellowbrick\n",
    "\n",
    "kmeans_mca3 = KMeans(init='random', n_init='auto', max_iter=100, random_state=42)\n",
    "visualizer = KElbowVisualizer(kmeans_mca3, k=(1,12))\n",
    "\n",
    "visualizer.fit(loading_heures_mca)    # Fit the data to the visualizer\n",
    "visualizer.show()    # Finalize and render the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4ee9cc-ace9-417c-bab2-bbf89d74b902",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(15,8))\n",
    "\n",
    "for k in range(2, 6):\n",
    "    kmeans_mca3 = KMeans(n_clusters=k, init='random', n_init='auto', max_iter=100, random_state=42)\n",
    "    q, mod = divmod(k, 2) \n",
    "    # Create SilhouetteVisualizer instance with KMeans instance\n",
    "    visualizer = SilhouetteVisualizer(kmeans_mca3, colors='yellowbrick', ax=ax[q-1][mod])\n",
    "    visualizer.fit(loading_heures_mca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff04f01-b033-45c3-8b4b-8a5bc35163e8",
   "metadata": {},
   "source": [
    "Comme pour le clustering K-means sur les données PCA, on trouve ici que le nombre idéal de clusters est 3 ou 4. On penche plus vers 4 pour voir si l'analyse avec PCA ou avec MCA est comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de37666e-6678-4798-a09d-6338e4f387c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#on fixe le nombre de clusters à 4\n",
    "kmeans_mca3 = KMeans(n_clusters=4, init='random', n_init='auto', max_iter=100, random_state=42)\n",
    "clusters_mca3 = kmeans_mca3.fit_predict(loading_heures_mca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02114546-ccd9-43e6-b298-ea4c32773475",
   "metadata": {},
   "source": [
    "Avant de continuer nos analyses, nous allons calculer la variance intra-classe de chaque cluster afin de s'assurer que les éléments d'un même cluster ont un comportement similaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5e4ea0-5a10-45d8-80f4-3aa3f2d3d18b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# distance de chaque point de données à son centre de cluster\n",
    "distances = kmeans_mca3.transform(loading_heures_mca)\n",
    "\n",
    "#variance intraclasse pour chaque cluster\n",
    "variances = []\n",
    "for cluster in range(kmeans_mca3.n_clusters):\n",
    "    cluster_distances = distances[kmeans_mca3.labels_ == cluster, cluster]\n",
    "    variance = np.var(cluster_distances)\n",
    "    variances.append(variance)\n",
    "\n",
    "# Affichage\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(range(kmeans_mca3.n_clusters), variances, color='skyblue')\n",
    "plt.xlabel('Clusters')\n",
    "plt.ylabel('Variance intra-classe')\n",
    "plt.title('Variance intra-classe par cluster')\n",
    "plt.xticks(range(kmeans_mca3.n_clusters), [f'Cluster {i+1}' for i in range(kmeans_mca3.n_clusters)])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5fb93b-10c5-4a54-9d7c-6548e00d277c",
   "metadata": {
    "tags": []
   },
   "source": [
    "Les variances intra-classes de chaque clusters sont très faibles donc on peut poursuivre nos analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a164149-0836-4e74-909c-7406d752c4fb",
   "metadata": {},
   "source": [
    "Le cluster 2 à une variance assez élevée comparée à celles des autres clusters qui sont plutot faibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38f2228-8488-4077-bf02-2c348bc4e408",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clusters_mca3 = kmeans_mca3.fit_predict(loading_heures_mca)\n",
    "loading_sub_mca3 = loading.iloc[:,:]\n",
    "loading_sub_mca3['cluster']=clusters_mca3\n",
    "mean_loading_mca3=loading_sub_mca3.groupby('cluster').mean()\n",
    "mean_loading_mca3.head()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "col= ['purple', 'blue'  ,'green','#FFFF00']\n",
    "\n",
    "# Affichage des 4 lignes sur le même graphique\n",
    "for i in range(4):\n",
    "    ax.plot(mean_loading_mca3.columns, mean_loading_mca3.iloc[i], label=f'Cluster {i+1}', color=col[i])\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Moyenne des chargements par cluster')\n",
    "plt.xlabel('Temps en heures')\n",
    "plt.ylabel('Moyenne des loading')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d0c207-a3a3-41fb-9976-549d49c6bfc2",
   "metadata": {},
   "source": [
    "L'évolution du chargement moyen des stations sur la semaine semble avoir le même comportement que pour le jeu de données regroupé par heure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20230f93-7f42-4248-b08b-16a9807aa92c",
   "metadata": {},
   "source": [
    "Ci dessous on peut visualiser ces clusters sur la carte de Paris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e4ad37-418e-4364-a7c3-64c6a12a9029",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f1 = px.scatter_mapbox(clusters_mca3, Position[:,1], Position[:,0], color=clusters_mca3, color_continuous_scale=[(0, '#800080'), (0.5, '#008080'), (1, '#FFFF00')], \n",
    "                        size_max=15, zoom=10,mapbox_style=\"carto-positron\", opacity = .9,\n",
    "                        title = 'clusters données complètes')\n",
    "\n",
    "f1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78136f39-aefe-41b7-9185-1a1b21ded6a1",
   "metadata": {},
   "source": [
    "### 6.3. Gaussian Mixture Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c350442-405d-4fad-8a5b-39a6792fac34",
   "metadata": {},
   "source": [
    "On effectue une deuxième méthode de clustering sur la mca précedente pour voir si certains résultats sont intéressants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1751d15a-d8f4-400f-a88b-1248555442fa",
   "metadata": {},
   "source": [
    "Le graphe suivant nous permet de selectionner le nombre de clusters optimal avec la méthode GMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa747cc4-5e53-43d3-b834-9782db396c7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "k_max = 15\n",
    "\n",
    "bic = []\n",
    "for k in range(2, k_max):\n",
    "    gmm = GaussianMixture(n_components=k, init_params='kmeans', n_init=3)\n",
    "    gmm.fit(loading_heures_mca)\n",
    "    bic.append(gmm.bic(loading_heures_mca))\n",
    "bic = np.array(bic)\n",
    "\n",
    "plt.scatter(range(2, k_max), bic)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8597e9e-9f4a-4125-bdfb-090ae484560b",
   "metadata": {},
   "source": [
    "Avec cette méthode on devrait garder entre 6 et 8 clusters. Pour la suite on garde seulement 4 clusters car avec 7-8 l'interprétation serait trop compliquée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170cb8ca-23a1-4389-bfad-d7cc6e162614",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "K = 4\n",
    "cmap = plt.get_cmap('Set3', K)\n",
    "\n",
    "gmm = GaussianMixture(n_components=K, n_init=4)\n",
    "clusters_gmm_heures_mca = gmm.fit_predict(loading_heures_mca)\n",
    "print(clusters_gmm_heures_mca)\n",
    "# --- #\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(loading_heures_mca.iloc[:,0], loading_heures_mca.iloc[:,1], c=clusters_gmm_heures_mca, s=1, linewidths=1, cmap='viridis')\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd015b7-2ee6-4ae5-9fc0-3e58c83f7113",
   "metadata": {},
   "source": [
    "Avant de continuer nos analyses\n",
    ", on va vérifier que la variance dans chaque cluster ne soit pas trop grande, ainsi les élèments d'un même cluster se comporteraient en moyenne de la même manière. <br> On affiche pour cela les boxplots des données de chaque cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce25514-355a-4e29-9071-287d669991ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aux = pd.DataFrame({\n",
    "    'label': ['Cluster ' + str(label) for label in clusters_gmm_heures_mca],\n",
    "    'proba': np.max(gmm.predict_proba(loading_heures_mca), axis=1)\n",
    "})\n",
    "sns.boxplot(x='label', y='proba', data=aux, palette='Set3', showfliers=False)\n",
    "plt.title('Cluster Probabilities')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7f0166-d86a-4f55-9dea-026f03f4e457",
   "metadata": {},
   "source": [
    "Les variances des données dans chaque cluster, représentée par la longueur des boxplots, est très faible pour les 4 clusters, on peut poursuivre nos analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d506d2-1f68-4189-a78d-e51a079c4017",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loading_sub_mca3 = loading.iloc[:,:]\n",
    "loading_sub_mca3['cluster']=clusters_gmm_heures_mca\n",
    "mean_loading_mca3=loading_sub_mca3.groupby('cluster').mean()\n",
    "mean_loading_mca3.head()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "col= ['purple', 'blue'  ,'green','#FFFF00']\n",
    "\n",
    "# Affichage des 4 lignes sur le même graphique\n",
    "for i in range(4):\n",
    "    ax.plot(mean_loading_mca3.columns, mean_loading_mca3.iloc[i], label=f'Cluster {i+1}', color=col[i])\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Moyenne des chargements par cluster')\n",
    "plt.xlabel('Temps en heures')\n",
    "plt.ylabel('Moyenne des loading')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cdcada-c039-45a2-9365-55222aab2d06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f1 = px.scatter_mapbox(clusters_gmm_heures_mca, Position[:,1], Position[:,0], color=clusters_gmm_heures_mca, color_continuous_scale=[(0, '#800080'), (0.5, '#008080'), (1, '#FFFF00')], \n",
    "                        size_max=15, zoom=10,mapbox_style=\"carto-positron\", opacity = .9,\n",
    "                        title = 'clusters données complètes')\n",
    "\n",
    "f1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11ed706-6ce7-43a2-997a-6d9a46d05f4e",
   "metadata": {},
   "source": [
    "Avec GMM sur la MCA, on retrouve à peu près les mêmes conclusions qu'avec les k-means/cah sur loading et df1. Le cluster 4 correspond aux stations de travail chargées le jour et vides la nuit. Le cluster 1 est l'inverse du cluster 4 et le cluster 3 correspond aux stations dont le chargement varie peu. Les clusters 1 et 2 pourraient correspondre à des zones résidentielles mais également fréquentés le week-end donc aussi à des zones de divertissement alors que le cluster 3 le chargement varie beaucoup moins le week-end donc beaucoup moins fréquenté."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f897c985-79be-457d-b718-0ed0c1099170",
   "metadata": {},
   "source": [
    "On crée une fonction qui prédit à quel cluster pourrait appartenir une nouvelle station implementée à une latitude x et une longitude y. On regarde la station la plus proche de celle-ci en terme de coordonnées et on lui attribue le même cluster que cette station. \\\n",
    "Dans notre exemple, la station avec une latitude 2.35 et une longitude 48.45 appartiendrait au cluster 2, ie au cluster des stations qui se chargent en journée qui correspond aux stations proche des lieux de travails. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc912a7e-1752-4667-90c3-2f9fde78b98c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def def_pred_station(coord1, coord2, coord, reskmeans):\n",
    "    min_distance = 1000\n",
    "    r = 1\n",
    "    for i in range(coord.shape[0]):\n",
    "        resultat = np.sqrt((coord1 - coord.iloc[i, 0])**2 + (coord2 - coord.iloc[i, 1])**2)\n",
    "        if resultat < min_distance:\n",
    "            min_distance = resultat\n",
    "            r = i\n",
    "    \n",
    "    result = reskmeans[r]\n",
    "    localisation = coord.iloc[r]\n",
    "    return result, localisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a5b631-8c8b-492a-8724-2c8bb3a9efbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def_pred_station(2.35 , 48.45, coord, clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8398dd1-744e-4fab-8ad1-303f8c6c23cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 7. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5225f8f-a0c9-43e2-bf7b-0578e23392f1",
   "metadata": {},
   "source": [
    "Dans ce projet, nous avons remarqué que le profil de chargement d'une station dépend de sa localisation. Le chargement varie surtout en fonction des heures de la journée mais un peu moins entre le week-end et la semaine. \\\n",
    "Dans nos méthodes de clustering K-Means et CAH, on a repéré 4 types de stations : \n",
    "- Ls stations qui se chargent en journée et qui se vident en soirée, qui correspondent aux zones de travail. Ces stations sont également en moyenne moins chargées et un peu moins active le week-end. \n",
    "\n",
    "- Les stations qui se chargent en soirée et se vide le matin : elles correspondent aux zones d'habitation. Leur chargement reste élevé le week-end et varie moins car les gens n'ont pas besoin de se rendre à leur lieu de travail. \n",
    "- Les stations avec un chargement élevé en moyenne mais dont le chargement ne varie pas beaucoup \n",
    "- les stations avec un chargement faible en moyenne et dont le chargement ne varie pas beaucoup. On a vu que les stations en altitude sont en majorité dans ce dernier cluster. \n",
    "\n",
    "Ces deux derniers types de clusters correspondent aux stations moins empruntées. \n",
    "\n",
    "Le GMM dépend du langage de programmation : en R il nous rend en moyenne 2/3 clusters : il différencie les stations par leur chargement moyen et non pas par la variabilité de leur chargement. En Python, il renvoie les mêmes clusters que CAH/K-Means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127214b9-8d77-411f-a73e-95f00ba88133",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc-autonumbering": false,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
